{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMRF1mBVnKUMRsEhXhahd5E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolfisberg/zhaw-ba-online/blob/main/tfrecord_writer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dnrq_4ftTcg8"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "import math\n",
        "import scipy\n",
        "import pathlib\n",
        "\n",
        "\n",
        "_FILES_PER_SHARD = 750\n",
        "_SPEECH_DATA_DIR = 'speech'\n",
        "_NOISE_DATA_DIR = 'noise'\n",
        "_VALIDATION_DATA_DIR = 'cv'\n",
        "_TRAINING_DATA_DIR = 'tr'\n",
        "_TEST_DATA_DIR = 'tt'\n",
        "_SHARD_BASE_NAME = 'shard'\n",
        "_SAMPLE_RATE = 16000\n",
        "\n",
        "\n",
        "def main():\n",
        "    create_tfrecords_from_directory(_SPEECH_DATA_DIR, add_ref_data=True)\n",
        "    create_tfrecords_from_directory(_NOISE_DATA_DIR, add_ref_data=False)\n",
        "\n",
        "\n",
        "def create_tfrecords_from_directory(dir, add_ref_data=False):\n",
        "    for data_dir in [_TRAINING_DATA_DIR, _TEST_DATA_DIR, _VALIDATION_DATA_DIR]:\n",
        "        data_dir_path = os.path.join('data', 'downsampled', dir, data_dir)\n",
        "        wav_files = librosa.util.find_files(directory=data_dir_path, ext=['wav'], recurse=False, case_sensitive=False)\n",
        "        number_of_shards = math.ceil(len(wav_files) / _FILES_PER_SHARD)\n",
        "\n",
        "        for shard_number in range(number_of_shards):\n",
        "            shard_name = f'{_SHARD_BASE_NAME}_{dir}_{data_dir}_{str(shard_number).rjust(4, \"0\")}.tfrecord'\n",
        "            shard_path = os.path.join('data', 'tfrecords', dir, shard_name)\n",
        "\n",
        "            with tf.io.TFRecordWriter(shard_path) as out:\n",
        "                lowerIndex = shard_number * _FILES_PER_SHARD\n",
        "                upperIndex = (shard_number + 1) * _FILES_PER_SHARD\n",
        "\n",
        "                for fileIndex in range(lowerIndex, upperIndex if upperIndex <= len(wav_files) else len(wav_files)):\n",
        "                    file_path = wav_files[fileIndex]\n",
        "                    # read via librosa\n",
        "                    y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "                    # read via tensorflow\n",
        "                    # raw_audio = tf.io.read_file(file_path)\n",
        "                    # y, sr = tf.audio.decode_wav(raw_audio)\n",
        "\n",
        "                    # read via scipy\n",
        "                    # sr, y = scipy.io.wavfile.read(file_path)\n",
        "\n",
        "                    if sr != _SAMPLE_RATE:\n",
        "                        y = librosa.to_mono(y)\n",
        "                        y = librosa.resample(y=y, orig_sr=sr, target_sr=_SAMPLE_RATE, res_type='kaiser_best', scale=True)\n",
        "\n",
        "                    if y.dtype != np.dtype(np.int16):\n",
        "                        y = (y / np.max(np.abs(y)) * np.iinfo(np.int16).max).astype(np.int16)\n",
        "\n",
        "                    if add_ref_data:\n",
        "                        file_name_stem = os.path.splitext(os.path.basename(file_path))[0][4:]\n",
        "                        ref_matches = list(pathlib.Path(data_dir_path).rglob(f'*{file_name_stem}*.[fF]0'))\n",
        "                        if len(ref_matches) != 1:\n",
        "                            print(f'Cannot find ref (f0) file for [ {file_path} ], skipping...')\n",
        "                            continue\n",
        "\n",
        "                        ref_data = np.genfromtxt(ref_matches[0], delimiter=' ')\n",
        "\n",
        "                        example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                            'data': _bytes_feature(y.tobytes()),\n",
        "                            'data_sampling_rate': _int64_feature([sr]),\n",
        "                            'data_num_channels': _int64_feature([1]),\n",
        "                            'data_width': _int64_feature([len(y)]),\n",
        "                            'pitch': _float_feature(ref_data.T[2]),\n",
        "                            'pitch_confidence': _float_feature(ref_data.T[3]),\n",
        "                        }))\n",
        "\n",
        "                    else:\n",
        "                        example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                            'data': _bytes_feature(y.tobytes()),\n",
        "                            'data_sampling_rate': _int64_feature([sr]),\n",
        "                            'data_num_channels': _int64_feature([1]),\n",
        "                            'data_width': _int64_feature([len(y)]),\n",
        "                        }))\n",
        "\n",
        "\n",
        "                    out.write(example.SerializeToString())\n",
        "\n",
        "\n",
        "def _int64_feature(value):\n",
        "    return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "\n",
        "def _bytes_feature(value):\n",
        "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def _float_feature(value):\n",
        "    return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
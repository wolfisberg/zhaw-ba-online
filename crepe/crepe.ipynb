{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_crepe.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolfisberg/zhaw-ba-online/blob/main/crepe_offline/crepe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Mtb6Yjf_bAg"
      },
      "source": [
        "# GPU Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVb9Waux_Ij3"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU5ZvlGglGDd"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7h2rENnSN3W"
      },
      "source": [
        "!pip install mir_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q42BY8BPSoL",
        "collapsed": true
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.interpolate\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import datetime\n",
        "import mir_eval\n",
        "import math\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8nh41ellB7K"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWZIc9-WSItM",
        "collapsed": true
      },
      "source": [
        "# Audio\n",
        "SNR_RANGE = (-5.0,20.0) #dB\n",
        "FRAME_LENGTH = 1024\n",
        "FRAME_STEP = 256\n",
        "MIN_RAND_GAIN = 0.05\n",
        "MAX_RAND_GAIN = 1.1\n",
        "SAMPLE_LENGTH = 3 #shorter than shortest noise/speech sample\n",
        "FS = 16000\n",
        "PITCH_SAMPLING_TIME = 0.01 # s\n",
        "PITCH_FRAME_LENGTH = 0.032 # s\n",
        "\n",
        "\n",
        "# Data\n",
        "BATCH_SIZE = 32\n",
        "NUM_FRAMES = 1 + (FS * SAMPLE_LENGTH - FRAME_LENGTH) // FRAME_STEP\n",
        "# NUM_FRAMES = 1\n",
        "\n",
        "# Training\n",
        "STEPS_PER_EPOCH = 500\n",
        "EPOCHS = 100\n",
        "VALIDATION_STEPS = 5\n",
        "\n",
        "\n",
        "# Directories\n",
        "_DATA_DIR = os.path.join('/content/drive/MyDrive/BA_2021/')\n",
        "_TFRECORDS_DIR = os.path.join(_DATA_DIR, 'tfrecords')\n",
        "\n",
        "SPEECH_DATA_TR_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'tr')\n",
        "NOISE_DATA_TR_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'tr')\n",
        "SPEECH_DATA_CV_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'cv')\n",
        "NOISE_DATA_CV_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'cv')\n",
        "SPEECH_DATA_TT_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'tt')\n",
        "NOISE_DATA_TT_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'tt')\n",
        "\n",
        "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "\n",
        "# Misc\n",
        "SEED = 2\n",
        "\n",
        "\n",
        "# Parsing\n",
        "PARSING_CONFIG_NOISE = {\n",
        "    'data': tf.io.VarLenFeature(tf.string),\n",
        "    'data_sampling_rate': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_num_channels': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_width': tf.io.VarLenFeature(tf.int64),\n",
        "}\n",
        "\n",
        "PARSING_CONFIG_SPEECH = {\n",
        "    'data': tf.io.VarLenFeature(tf.string),\n",
        "    'data_sampling_rate': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_num_channels': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_width': tf.io.VarLenFeature(tf.int64),\n",
        "    'pitch': tf.io.VarLenFeature(tf.float32),\n",
        "    'pitch_confidence': tf.io.VarLenFeature(tf.float32),\n",
        "}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DQaQ8neunsZ"
      },
      "source": [
        "print(NOISE_DATA_TR_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-kwHYrpmCgl"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmb9w4ACwoUi"
      },
      "source": [
        "## Copy Data to Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYKlRsmDwsKM"
      },
      "source": [
        "DATA_DIR_LOCAL = '/content/data'\n",
        "\n",
        "if not os.path.exists(DATA_DIR_LOCAL):\n",
        "    os.mkdir(DATA_DIR_LOCAL)\n",
        "    \n",
        "    RECORD_DIR_LOCAL = os.path.join(DATA_DIR_LOCAL, 'tfrecords')\n",
        "    shutil.copytree(_TFRECORDS_DIR, RECORD_DIR_LOCAL)\n",
        "\n",
        "\n",
        "_TFRECORDS_DIR = os.path.join(DATA_DIR_LOCAL, 'tfrecords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awsl19RfyOii"
      },
      "source": [
        "print(_TFRECORDS_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlkFt3Nvsqn-"
      },
      "source": [
        "## Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhwJchGumFSo"
      },
      "source": [
        "def _parse_noise_record(serialized_example):\n",
        "    parsed_features = tf.io.parse_single_example(serialized_example, features=PARSING_CONFIG_NOISE)\n",
        "    decoded_features = {\n",
        "        \"data_num_channels\": tf.cast(parsed_features[\"data_num_channels\"].values[0], tf.int32),\n",
        "        \"data_sampling_rate\": tf.cast(parsed_features[\"data_sampling_rate\"].values[0], tf.int32),\n",
        "        \"data_width\": tf.cast(parsed_features[\"data_width\"].values[0], tf.int32),\n",
        "    }\n",
        "    data = tf.io.decode_raw(parsed_features['data'].values[0], tf.int16)\n",
        "    decoded_features.update({\"data\": data})\n",
        "    return decoded_features\n",
        "\n",
        "\n",
        "def _parse_speech_record(serialized_example):\n",
        "    parsed_features = tf.io.parse_single_example(serialized_example, features=PARSING_CONFIG_SPEECH)\n",
        "    decoded_features = {\n",
        "        \"data_num_channels\": tf.cast(parsed_features[\"data_num_channels\"].values[0], tf.int32),\n",
        "        \"data_sampling_rate\": tf.cast(parsed_features[\"data_sampling_rate\"].values[0], tf.int32),\n",
        "        \"data_width\": tf.cast(parsed_features[\"data_width\"].values[0], tf.int32),\n",
        "        \"pitch\": tf.cast(parsed_features['pitch'].values, tf.float32),\n",
        "        \"pitch_confidence\": tf.cast(parsed_features['pitch_confidence'].values, tf.float32),\n",
        "    }\n",
        "    data = tf.io.decode_raw(parsed_features['data'].values[0], tf.int16)\n",
        "    decoded_features.update({\"data\": data})\n",
        "    return decoded_features\n",
        "\n",
        "\n",
        "def _mix_noisy_speech(speech, noise):\n",
        "    speech_pow = tf.math.reduce_euclidean_norm(speech)\n",
        "    noise_pow = tf.math.reduce_euclidean_norm(noise)\n",
        "\n",
        "    min_SNR = SNR_RANGE[0]\n",
        "    max_SNR = SNR_RANGE[1]\n",
        "    snr_current = 20.0*tf.math.log(speech_pow/noise_pow)/tf.math.log(10.0)\n",
        "    snr_target = tf.random.uniform((),minval=min_SNR,maxval=max_SNR)\n",
        "\n",
        "    noise = noise * tf.math.pow(10.0,(snr_current-snr_target)/20.0)\n",
        "    noisy_speech = speech+noise\n",
        "\n",
        "    return speech, noise, noisy_speech\n",
        "\n",
        "\n",
        "def _interpolate_pitch(pitch,t):\n",
        "    pitches = pitch.numpy()\n",
        "    t = t.numpy()\n",
        "    t_pitch = np.arange(0, len(pitch)) * PITCH_SAMPLING_TIME + PITCH_FRAME_LENGTH / 2\n",
        "    f = scipy.interpolate.interp1d(t_pitch, pitch, 'nearest')\n",
        "    return f(t).astype(np.float32)\n",
        "\n",
        "def convert_hz_to_cent(f,fref=10.0):\n",
        "    return mir_eval.melody.hz2cents(np.array(f), fref)\n",
        "\n",
        "def calc_bin(freq_cent, cents_per_bin = 20, lower_bound_freq=32.7):  \n",
        "    freq_cent = np.squeeze(freq_cent)\n",
        "    #freq_cent = np.reshape(freq_cent, (1, freq_cent[0]*freq_cent[1]))\n",
        "    lower_bound_freq_cent = mir_eval.melody.hz2cents(np.array([lower_bound_freq]))\n",
        "    bin = (freq_cent - lower_bound_freq_cent) / np.array([cents_per_bin])\n",
        "    #print(np.clip(bin, 0, 359))\n",
        "    return np.clip(bin, 0, 359)\n",
        "    #return min(359, max(0, bin))\n",
        "\n",
        "def calc_y(f_groundtruth, n_bins = 360):\n",
        "    c_true = calc_bin(f_groundtruth)\n",
        "    return create_bin_vector(c_true)\n",
        "\n",
        "def create_bin_vector(c_true):\n",
        "    cis = np.arange(360)\n",
        "    # cis = np.tile(cis, (len(c_true), 1))\n",
        "    y = [gaussian_blur(cis, i) for i in c_true]\n",
        "    return np.squeeze(y)\n",
        "    \n",
        "def gaussian_blur(ci, ctrue):\n",
        "    return np.exp(-(ci-ctrue)**2/(2.0*25.0**2))\n",
        "\n",
        "@tf.function\n",
        "def _interpolate_pitch_tf(pitch,t):\n",
        "    y = tf.py_function(_interpolate_pitch,[pitch,t], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "@tf.function\n",
        "def _convert_hz_to_cent(pitch):\n",
        "    y = tf.py_function(convert_hz_to_cent,[pitch], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "@tf.function\n",
        "def _calc_y(pitch_cents):\n",
        "    y = tf.py_function(calc_y,[pitch_cents], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "def _calc_features(speech_data, noise_data):\n",
        "    speech = tf.squeeze(tf.cast(speech_data[\"data\"], tf.float32))\n",
        "    noise = tf.squeeze(tf.cast(noise_data[\"data\"], tf.float32))\n",
        "    speech = speech / tf.int16.max\n",
        "    noise = noise / tf.int16.max\n",
        "\n",
        "    random_start_idx = int(tf.round(tf.random.uniform([], maxval=(\n",
        "             tf.cast(len(noise), tf.float32) - SAMPLE_LENGTH * FS - PITCH_SAMPLING_TIME))))\n",
        "    noise = noise[random_start_idx:random_start_idx + SAMPLE_LENGTH * FS]\n",
        "\n",
        "    random_start_idx = int(tf.round(tf.random.uniform([], minval=161, maxval=(\n",
        "            tf.cast(len(speech), tf.float32) - SAMPLE_LENGTH * FS - 161))))\n",
        "    speech = speech[random_start_idx:random_start_idx + SAMPLE_LENGTH * FS]   \n",
        "\n",
        "    #SNR_range = SNR_RANGE\n",
        "    frame_length = FRAME_LENGTH\n",
        "    frame_step = FRAME_STEP\n",
        "    speech, noise, noisy = _mix_noisy_speech(speech, noise)\n",
        "\n",
        "    random_gain = tf.math.exp(\n",
        "        tf.random.uniform([], minval=tf.math.log(MIN_RAND_GAIN), maxval=tf.math.log(MAX_RAND_GAIN)))\n",
        "    noisy = random_gain * noisy\n",
        "\n",
        "    noisy_frames = tf.signal.frame(noisy, frame_length, frame_step)\n",
        "    speech_frames = tf.signal.frame(speech, frame_length, frame_step)\n",
        "    noisy_frames = tf.squeeze(noisy_frames)\n",
        "    speech_frames = tf.squeeze(speech_frames)\n",
        "    #noisy_stft = tf.signal.stft(noisy,frame_length,frame_step)\n",
        "    # frame_times = random_start_idx / FS + tf.range(0, NUM_FRAMES) * frame_step / FS + frame_length / FS\n",
        "    frame_times = random_start_idx / FS + tf.range(0, NUM_FRAMES) * frame_step / FS + frame_length / FS\n",
        "    \n",
        "    pitch = tf.squeeze(speech_data[\"pitch\"])    \n",
        "    pitch_confidence = tf.squeeze(speech_data[\"pitch_confidence\"])\n",
        "    #pitch = tf.where(pitch_confidence>config['pitch_confidence_threshold'],pitch,0)\n",
        "    pitch_interpolated = _interpolate_pitch_tf(pitch, frame_times)\n",
        "    pitch_interpolated_cents = _convert_hz_to_cent(pitch_interpolated)\n",
        "    pitch_bins = _calc_y(pitch_interpolated_cents)\n",
        "    return noisy_frames, pitch_bins"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPVV-n86kqJb"
      },
      "source": [
        "a = np.random.randn(184,1)\n",
        "mir_eval.melody.hz2cents(np.squeeze(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0TKt5eSs0SF"
      },
      "source": [
        "## Provide Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiU-wMWPs2dZ"
      },
      "source": [
        "def get_training_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_TR_DIR, file) for file in os.listdir(SPEECH_DATA_TR_DIR)])\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_TR_DIR, file) for file in os.listdir(NOISE_DATA_TR_DIR)])\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "    return dataset_features\n",
        "\n",
        "\n",
        "def get_validation_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_CV_DIR, file) for file in os.listdir(SPEECH_DATA_CV_DIR)])\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_CV_DIR, file) for file in os.listdir(NOISE_DATA_CV_DIR)])\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset_features\n",
        "\n",
        "\n",
        "def get_test_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_TT_DIR, file) for file in os.listdir(SPEECH_DATA_TT_DIR)])\n",
        "    # speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(10).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_TT_DIR, file) for file in os.listdir(NOISE_DATA_TT_DIR)])\n",
        "    # noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(10).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdIXYFTDoN1j"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLnYza9woPzS"
      },
      "source": [
        "## CREPE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eqf-W1MYml8T"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Reshape, Conv2D, BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPool2D, Dropout, Permute, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "MODEL_USED = 'crepe'\n",
        "LOG_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'logs', TIMESTAMP)\n",
        "if not os.path.exists(LOG_DIR):\n",
        "    os.makedirs(LOG_DIR)\n",
        "CHECKPOINT_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'checkpoints', TIMESTAMP)\n",
        "if not os.path.exists(CHECKPOINT_DIR):\n",
        "    os.makedirs(CHECKPOINT_DIR)\n",
        "\n",
        "\n",
        "def get_model_crepe():\n",
        "    layers = [1, 2, 3, 4, 5, 6]\n",
        "    filters = [n * 32 for n in [32, 4, 4, 4, 8, 16]]\n",
        "    widths = [512, 64, 64, 64, 64, 64]\n",
        "    strides = [(1, 4), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]\n",
        "\n",
        "    x = Input(shape=(184,1024), name='input', dtype='float32')\n",
        "    y = Reshape(target_shape=(184, 1024, 1), name='input-reshape')(x)\n",
        "\n",
        "    for l, f, w, s in zip(layers, filters, widths, strides):\n",
        "        y = Conv2D(f, (1, w), strides=s, padding='same',\n",
        "                   activation='relu', name=\"conv%d\" % l)(y)\n",
        "        y = BatchNormalization(name=\"conv%d-BN\" % l)(y)\n",
        "        y = MaxPool2D(pool_size=(1, 2), strides=None, padding='valid',\n",
        "                      name=\"conv%d-maxpool\" % l)(y)\n",
        "        y = Dropout(0.25, name=\"conv%d-dropout\" % l)(y)\n",
        "\n",
        "    y = Reshape(target_shape=(184, 2048), name='output-reshape')(y)\n",
        "    y = Dense(1, name=\"classifier\")(y)\n",
        "\n",
        "    model = Model(inputs=x, outputs=y)\n",
        "    model.compile('adam', 'mse', metrics=['mse', 'mae'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vISBvnU1vxCD"
      },
      "source": [
        "print(LOG_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmKx4gLkKjwQ"
      },
      "source": [
        "## Crepe without time component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPygi-4sKooq"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Reshape, Conv2D, BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPool2D, Dropout, Permute, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "MODEL_USED = 'crepe'\n",
        "LOG_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'logs', TIMESTAMP)\n",
        "if not os.path.exists(LOG_DIR):\n",
        "    os.makedirs(LOG_DIR)\n",
        "CHECKPOINT_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'checkpoints', TIMESTAMP)\n",
        "if not os.path.exists(CHECKPOINT_DIR):\n",
        "    os.makedirs(CHECKPOINT_DIR)\n",
        "\n",
        "\n",
        "def get_model_crepe():\n",
        "    layers = [1, 2, 3, 4, 5, 6]\n",
        "    filters = [n * 32 for n in [32, 4, 4, 4, 8, 16]]\n",
        "    widths = [512, 64, 64, 64, 64, 64]\n",
        "    strides = [(4, 1), (1, 1), (1, 1), (1, 1), (1, 1), (1, 1)]\n",
        "\n",
        "    x = Input(shape=(1024,), name='input', dtype='float32')\n",
        "    y = Reshape(target_shape=(1024, 1, 1), name='input-reshape')(x)\n",
        "\n",
        "    for layer, filters, width, strides in zip(layers, filters, widths, strides):\n",
        "        y = Conv2D(filters, (width, 1), strides=strides, padding='same',\n",
        "                   activation='relu', name=\"conv%d\" % layer)(y)\n",
        "        y = BatchNormalization(name=\"conv%d-BN\" % layer)(y)\n",
        "        y = MaxPool2D(pool_size=(2, 1), strides=None, padding='valid',\n",
        "                         name=\"conv%d-maxpool\" % layer)(y)\n",
        "        y = Dropout(0.25, name=\"conv%d-dropout\" % layer)(y)\n",
        "\n",
        "    y = Permute((2, 1, 3), name=\"transpose\")(y)\n",
        "    y = Flatten(name=\"flatten\")(y)\n",
        "    y = Dense(360, activation='sigmoid', name=\"classifier\")(y)\n",
        "\n",
        "    model = Model(inputs=x, outputs=y)\n",
        "    model.compile('adam', 'binary_crossentropy', metrics=['mse', 'mae'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-SpsYhaCNV"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g6YW7mUtA64"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uU1pyCDPm8C7"
      },
      "source": [
        "dataset_training = get_training_data()\n",
        "dataset_validation = get_validation_data()\n",
        "dataset_test = get_test_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvgm5FjDyhNo"
      },
      "source": [
        "## Debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjtDpgLl4Qft"
      },
      "source": [
        "inp, outp = next(iter(dataset_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgEFuKgwWtdP"
      },
      "source": [
        "print(inp.shape)\n",
        "print(outp.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7-RLkC8cxmR"
      },
      "source": [
        "print(outp[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bQ8U-qMcTSX"
      },
      "source": [
        "plt.plot(outp[0][15])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yM7zuEJz6nUB"
      },
      "source": [
        "new_dataset = dataset_training.unbatch().unbatch().shuffle(1000).batch(32)\n",
        "c =iter(new_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmFIi57oflhY"
      },
      "source": [
        "inp, outp = next(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3c7PbLXfre9"
      },
      "source": [
        "inp.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh9JJV9g6slY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZO1Ljochb5W"
      },
      "source": [
        "new_dataset = dataset_training.unbatch().shuffle(5000).batch(32)\n",
        "c =iter(new_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaEKXyFmgPRH"
      },
      "source": [
        "inp, outp = next(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EKDyx7LLHtZ"
      },
      "source": [
        "print(inp.shape)\n",
        "print(outp.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_JctoYxAQPb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jup6KCfQj3VK"
      },
      "source": [
        "%timeit inp, outp = next(c)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvxKNu3-17_U"
      },
      "source": [
        "%timeit inp,  outp = next(iter(dataset_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_wQECIKQZao"
      },
      "source": [
        "(10)*(2**(5446.58544922/1200.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHi5MdmzJtIS"
      },
      "source": [
        "y = outp[28]\n",
        "plt.figure()\n",
        "plt.plot(y)\n",
        "plt.plot(np.argmax(y),np.max(y),'x')\n",
        "plt.text(np.argmax(y)+10,np.max(y),f'max={np.max(y):.1f} @ bin {np.argmax(y)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ky7INWDZwj9S"
      },
      "source": [
        "print(outp[25][275])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRo4lH2WMvgj"
      },
      "source": [
        "plt.plot(outp[25])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjwct6engS6w"
      },
      "source": [
        "print(outp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbBpJMHXSuTh"
      },
      "source": [
        "inp, outp = next(iter(dataset_training))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI9yBWUKS1S1"
      },
      "source": [
        "pred = model.predict(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKDPArT8vHuh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17HSxBSuWqmG"
      },
      "source": [
        "print(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I22Kwb8YpY4S"
      },
      "source": [
        "plt.plot(pred[1])\n",
        "plt.plot(outp[1])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxVWOsDX0Fku"
      },
      "source": [
        "print(next(iter(dataset_training)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dzEiCs_tDcJ"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poP21a6TnLHO"
      },
      "source": [
        "model = get_model_crepe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "33_wEPK8nNfC"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbVgnmcitIjt"
      },
      "source": [
        "## Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHZ4eMqMnchd",
        "collapsed": true
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/BA_2021/crepe/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn0JRWrccNJH"
      },
      "source": [
        "# JUST USE IF CONTINUING TRAINING\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/BA_2021/crepe/checkpoints/20210427-145400'\n",
        "LOGDIR = '/content/drive/MyDrive/BA_2021/crepe/logs/20210427-145400'\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/crepe/checkpoints', '20210427-145400', '50-2063.93.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OMUc5cRQnSNQ"
      },
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(LOG_DIR, histogram_freq=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(CHECKPOINT_DIR,'{epoch:02d}-{val_loss:.2f}.hdf5'))\n",
        "\n",
        "callbacks = [checkpoint, tensorboard_callback]\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    dataset_training,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs=50,\n",
        "    initial_epoch=30,\n",
        "    verbose = 1,\n",
        "    validation_data = dataset_validation,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks = callbacks)\n",
        "    \n",
        "loss = model.evaluate(dataset_test, steps=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg0cbO1z2DTj"
      },
      "source": [
        "prediction_sample = next(iter(dataset_test))[0]\n",
        "print(prediction_sample)\n",
        "prediction = model.predict(prediction_sample)\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgj1DGAaAo0v"
      },
      "source": [
        "plt.plot(prediction[1], 'g')\n",
        "#plt.plot(test_prediciton[1], 'r')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqR7EegbnWtc"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4eqzLWm0XrP"
      },
      "source": [
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/crepe/checkpoints', '20210422-163259', '100-0.12.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAxbdnKj-B3f"
      },
      "source": [
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/crepe/checkpoints', '20210413-102858', '20-0.20.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P70IKoz7R61X"
      },
      "source": [
        "model.evaluate(dataset_test, steps=70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVozVO6-vtO3"
      },
      "source": [
        "# Prediction Metrics Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-XJKS-W4Q2D"
      },
      "source": [
        "classifier_lowest_hz = 32.70\n",
        "classifier_lowest_cent = mir_eval.melody.hz2cents(np.array([classifier_lowest_hz]))[0]\n",
        "classifier_cents_per_bin = 20\n",
        "classifier_octaves = 6\n",
        "classifier_total_bins = int((1200 / classifier_cents_per_bin) * classifier_octaves)\n",
        "classifier_cents = np.linspace(0, (classifier_total_bins - 1) * classifier_cents_per_bin, classifier_total_bins) + classifier_lowest_cent\n",
        "\n",
        "def to_weighted_average_cents(label):\n",
        "    if label.ndim == 1:\n",
        "        productsum = np.sum(label * classifier_cents)\n",
        "        weightsum = np.sum(label)\n",
        "        return productsum / weightsum\n",
        "    if label.ndim == 2:\n",
        "        productsum = np.dot(label, classifier_cents)\n",
        "        weightsum = np.sum(label, axis=1)\n",
        "        return productsum / weightsum\n",
        "    raise Exception(\"label should be either 1d or 2d ndarray\")\n",
        "\n",
        "def to_local_average_cents(salience, center=None):\n",
        "    \"\"\"\n",
        "    find the weighted average cents near the argmax bin\n",
        "    \"\"\"\n",
        "    if not hasattr(to_local_average_cents, 'cents_mapping'):\n",
        "        # the bin number-to-cents mapping\n",
        "        to_local_average_cents.cents_mapping = (\n",
        "                np.linspace(0, 7180, 360) + 1997.3794084376191)\n",
        "\n",
        "    if salience.ndim == 1:\n",
        "        if center is None:\n",
        "            center = int(np.argmax(salience))\n",
        "        start = max(0, center - 4)\n",
        "        end = min(len(salience), center + 5)\n",
        "        salience = salience[start:end]\n",
        "        product_sum = np.sum(\n",
        "            salience * to_local_average_cents.cents_mapping[start:end])\n",
        "        weight_sum = np.sum(salience)\n",
        "        return product_sum / weight_sum\n",
        "    if salience.ndim == 2:\n",
        "        return np.array([to_local_average_cents(salience[i, :]) for i in\n",
        "                         range(salience.shape[0])])\n",
        "\n",
        "    raise Exception(\"label should be either 1d or 2d ndarray\")\n",
        "\n",
        "def convert_cent_to_hz(c,fref=10.0):\n",
        "    return fref*2**(c/1200.0)\n",
        "\n",
        "def raw_pitch_accuracy_cent(true_cents, predicted_cents, cent_tolerence=50):\n",
        "    counter_true = 0\n",
        "    counter_false = 0\n",
        "    for i in range(len(true_cents)):\n",
        "        if abs(predicted_cents[i] - true_cents[i]) <= 50.0:\n",
        "            counter_true += 1\n",
        "        else:\n",
        "            counter_false += 1\n",
        "    if counter_true > 0:\n",
        "        result = counter_true / (counter_true + counter_false) * 100\n",
        "    else:\n",
        "        result = 0\n",
        "    return result\n",
        "\n",
        "def raw_pitch_accuracy_hz(true_hz, predicted_hz):\n",
        "    counter_true = 0\n",
        "    counter_false = 0\n",
        "    for i in range(len(true_hz)):\n",
        "        if abs(predicted_hz[i] - true_hz[i]) <= (true_hz[i] * 0.02):\n",
        "            counter_true += 1\n",
        "        else:\n",
        "            counter_false += 1\n",
        "    if counter_true > 0:\n",
        "        result = counter_true / (counter_true + counter_false) * 100\n",
        "    else:\n",
        "        result = 0\n",
        "    return result\n",
        "\n",
        "def standard_deviation_cent(true_cents, predicted_cents):\n",
        "    diff = abs(predicted_cents - true_cents)\n",
        "    avg = np.mean(diff)\n",
        "    diff = np.square(diff - avg)\n",
        "    sum = np.sum(diff)\n",
        "    std_dev = np.sqrt((sum / (len(diff)-1)))\n",
        "    return std_dev\n",
        "\n",
        "def standard_deviation_hz(true_hz, predicted_hz):\n",
        "    diff = abs(predicted_hz - true_hz)\n",
        "    avg = np.mean(diff)\n",
        "    diff = np.square(diff - avg)\n",
        "    sum = np.sum(diff)\n",
        "    std_dev = np.sqrt((sum / (len(diff)-1)))\n",
        "    return std_dev\n",
        "\n",
        "def mean_absolute_error_cent(true_cents, predicted_cents):\n",
        "    diff = abs(predicted_cents - true_cents)\n",
        "    mae = np.mean(diff)\n",
        "    return mae\n",
        "\n",
        "def mean_absolute_error_hz(true_hz, predicted_hz):\n",
        "    diff = abs(predicted_hz - true_hz)\n",
        "    mae = np.mean(diff)\n",
        "    return mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O2yL6xTM4iD"
      },
      "source": [
        "def histogram(diff):\n",
        "# def histogram(true_hz, predicted_hz):\n",
        "    #diff = abs(predicted_hz - true_hz)  \n",
        "    n_bins = 250\n",
        "\n",
        "    x = diff\n",
        "    y = true_hz\n",
        "\n",
        "    # fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "    # We can set the number of bins with the `bins` kwarg\n",
        "    plt.figure()\n",
        "    plt.hist(x, bins=n_bins)\n",
        "    # axs[0].hist(x, bins=n_bins)\n",
        "    #plt.xlim([-200, 200])\n",
        "    plt.ylim([0, 10000])\n",
        "    plt.xlabel(\"Error in Hertz\")\n",
        "    plt.ylabel(\"Number of Errors\")\n",
        "    plt.show()\n",
        "    # axs[1].hist(x, bins=n_bins)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnoXGQL06WdR"
      },
      "source": [
        "def prediction():\n",
        "    predicted_c = []\n",
        "    true_c = []\n",
        "    for inp, outp in dataset_test:\n",
        "        predicted = model.predict(inp)\n",
        "        true_cents = to_local_average_cents(outp)\n",
        "        true_c.append(true_cents)\n",
        "        predicted_cents = to_local_average_cents(np.squeeze(predicted))\n",
        "        predicted_c.append(predicted_cents)\n",
        "\n",
        "    true_c = np.reshape(np.array(true_c), (1, (len(true_c)*len(true_c[0]))))\n",
        "    true_c = np.squeeze(true_c)\n",
        "    true_hz = convert_cent_to_hz(true_c)\n",
        "    predicted_c = np.reshape(np.array(predicted_c), (1, (len(predicted_c)*len(predicted_c[0]))))\n",
        "    predicted_c = np.squeeze(predicted_c)\n",
        "    predicted_hz = convert_cent_to_hz(predicted_c)\n",
        "    diff = true_hz - predicted_hz\n",
        "    return predicted_hz, true_hz, true_c, predicted_c, diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh3HIl3f7ONH"
      },
      "source": [
        "predicted_hz, true_hz, true_cent, predicted_cent, diff = prediction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcrLxYRs5V73"
      },
      "source": [
        "print(predicted_hz.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUs_jXsA-8h5"
      },
      "source": [
        "combined = zip(true_hz, predicted_hz)\n",
        "filtered = [x for x in list(combined) if x[0] > 0]\n",
        "filtered_unzipped = np.array(list(zip(*filtered)))\n",
        "diff_filtered = filtered_unzipped[0] - filtered_unzipped[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTXf2ccNfn1W"
      },
      "source": [
        "combined_cent = zip(true_cent, predicted_cent)\n",
        "filtered_cent = [x for x in list(combined_cent) if x[0] > 2072.0]\n",
        "# filtered_c_unzipped = np.array(list(zip(*filtered_cent)))\n",
        "# diff_filtered_cent = filtered_c_unzipped[0] - filtered_c_unzipped[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH9mUvpffcgW"
      },
      "source": [
        "std_dev_hz = np.std(diff_filtered)\n",
        "mae_hz = mean_absolute_error_hz(true_hz=filtered_unzipped[0], predicted_hz=filtered_unzipped[1])\n",
        "mean_hz = np.mean(diff_filtered)\n",
        "median_hz = np.median(diff_filtered)\n",
        "# std_dev, avg = standard_deviation_hz(true_hz=filtered_unzipped[0], predicted_hz=filtered_unzipped[1])\n",
        "rpa_cent = raw_pitch_accuracy_cent(filtered_cent[0], filtered_cent[1])\n",
        "# histo = histogram(diff)\n",
        "quantile_05 = np.quantile(diff_filtered, 0.05)\n",
        "quantile_95 = np.quantile(diff_filtered, 0.95)\n",
        "min = np.min(diff_filtered)\n",
        "max = np.max(diff_filtered)\n",
        "\n",
        "histo_true = histogram([x[0] - x[1] for x in filtered])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhTJzY9A8b7m"
      },
      "source": [
        "std_dev_hz = np.std(diff)\n",
        "mae_hz = mean_absolute_error_hz(true_hz, predicted_hz)\n",
        "mean_hz = np.mean(diff)\n",
        "median_hz = np.median(diff)\n",
        "# std_dev, avg = standard_deviation_hz(true_hz, predicted_hz)\n",
        "rpa_cent = raw_pitch_accuracy_cent(true_cent, predicted_cent)\n",
        "histo = histogram(diff)\n",
        "quantile_05 = np.quantile(diff, 0.05)\n",
        "quantile_95 = np.quantile(diff, 0.95)\n",
        "min = np.min(diff)\n",
        "max = np.max(diff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCTj31ObAZ4O"
      },
      "source": [
        "print(\"Stdabweichung:\", \"%.2f\" % std_dev_hz )\n",
        "print(\"Avg in Hz:\", \"%.2f\" % mean_hz)\n",
        "print(\"MAE in Hz:\", \"%.2f\" % mae_hz)\n",
        "print(\"5% Quantil:\", \"%.2f\" % quantile_05)\n",
        "print(\"95% Quantil:\", \"%.2f\" % quantile_95)\n",
        "print(\"Median in Hz:\", \"%.2f\" %median_hz)\n",
        "print(\"Max in Hz:\",\"%.2f\" % max)\n",
        "print(\"Min in Hz:\", \"%.2f\" % min)\n",
        "print(\"RPA in Cent:\", \"%.2f\" % rpa_cent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tfibfpLa5nv"
      },
      "source": [
        "def prediction_metrics():\n",
        "    predicted_c = []\n",
        "    true_c = []\n",
        "    \n",
        "    for inp, outp in dataset_test:\n",
        "        predicted = model.predict(inp)\n",
        "        true_cents = to_local_average_cents(outp)\n",
        "        true_c.append(true_cents)\n",
        "        predicted_cents = to_local_average_cents(np.squeeze(predicted))\n",
        "        predicted_c.append(predicted_cents)\n",
        "    \n",
        "    true_c = np.reshape(np.array(true_c), (1, (len(true_c)*len(true_c[0]))))\n",
        "    true_c = np.squeeze(true_c)\n",
        "    true_hz = convert_cent_to_hz(true_c)\n",
        "    predicted_c = np.reshape(np.array(predicted_c), (1, (len(predicted_c)*len(predicted_c[0]))))\n",
        "    predicted_c = np.squeeze(predicted_c)\n",
        "    predicted_hz = convert_cent_to_hz(predicted_c)\n",
        "    \n",
        "    # Raw Pitch Accuracy\n",
        "    rpa_cent = raw_pitch_accuracy_cent(true_c, predicted_c)\n",
        "    rpa_hz = raw_pitch_accuracy_hz(true_hz, predicted_hz)\n",
        "\n",
        "    # Standard Deviation\n",
        "    std_dev_cent = standard_deviation_cent(true_c, predicted_c)\n",
        "    std_dev_hz = standard_deviation_hz(true_hz, predicted_hz)\n",
        "\n",
        "    # Mean Absolute Error\n",
        "    mae_cent = mean_absolute_error_cent(true_c, predicted_c)\n",
        "    mae_hz = mean_absolute_error_hz(true_hz, predicted_hz)\n",
        "    return rpa_cent, rpa_hz, std_dev_cent, std_dev_hz, mae_cent, mae_hz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOvlZw9tbnl7"
      },
      "source": [
        "pred = prediction_metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIcO858ubuTv"
      },
      "source": [
        "print(pred[0], pred[1], pred[2], pred[3], pred[4], pred[5])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPA7rTSjMgoc"
      },
      "source": [
        "inp, outp = next(iter(dataset_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKZMk4CsCKuc"
      },
      "source": [
        "cents = to_weighted_average_cents(outp)\n",
        "predicted = model.predict(inp, steps=1)\n",
        "predicted = np.squeeze(predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHVa2ryhZ4s3"
      },
      "source": [
        "# Prediction Metrics With Time Component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1Qq-OIvZ4s3"
      },
      "source": [
        "inp, outp = next(iter(dataset_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WELMrRT3Z4s3"
      },
      "source": [
        "pred = model.predict(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6YX48htZ4s4"
      },
      "source": [
        "plt.plot(pred[6])\n",
        "plt.plot(outp[6])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNpNuSzHZ4s4"
      },
      "source": [
        "def raw_pitch_accuracy_cent(true_cent, predicted_cent):\n",
        "    counter_true = 0\n",
        "    counter_false = 0\n",
        "    for i in range(len(true_hz)):\n",
        "        if np.abs(true_hz[i] - predicted_hz[i]) <= 50.0 :\n",
        "            counter_true += 1\n",
        "        else:\n",
        "            counter_false += 1\n",
        "    if counter_true > 0:\n",
        "        result = counter_true / (counter_true + counter_false) * 100\n",
        "    else:\n",
        "        result = 0\n",
        "    return result\n",
        "\n",
        "def standard_deviation_hz(true_hz, predicted_hz):\n",
        "    diff = abs(predicted_hz - true_hz)\n",
        "    avg = np.mean(diff)\n",
        "    \n",
        "    diff = np.square(diff - avg)\n",
        "    sum = np.sum(diff)\n",
        "    std_dev = np.sqrt((sum / (len(diff)-1)))\n",
        "    return std_dev, avg\n",
        "\n",
        "def mean_absolute_error_hz(true_hz, predicted_hz):\n",
        "    diff = abs(predicted_hz - true_hz)\n",
        "    mae = np.mean(diff)\n",
        "    return mae"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXRgtrydZ4s4"
      },
      "source": [
        "def standard_deviation_hz_np(true_hz, predicted_hz):\n",
        "    diff = abs(predicted_hz - true_hz)\n",
        "    avg = np.mean(diff)\n",
        "    std_dev = np.std(diff)\n",
        "    return std_dev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6kPyt04Z4s4"
      },
      "source": [
        "def histogram(diff):\n",
        "# def histogram(true_hz, predicted_hz):\n",
        "    #diff = abs(predicted_hz - true_hz)  \n",
        "    n_bins = 250\n",
        "\n",
        "    x = diff\n",
        "    y = true_hz\n",
        "\n",
        "    # fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "    # We can set the number of bins with the `bins` kwarg\n",
        "    plt.figure()\n",
        "    plt.hist(x, bins=n_bins)\n",
        "    # axs[0].hist(x, bins=n_bins)\n",
        "    plt.xlim([-250, -100])\n",
        "    plt.ylim([0, 1000])\n",
        "    plt.xlabel(\"Error in Hertz\")\n",
        "    plt.ylabel(\"Number of Errors\")\n",
        "    plt.show()\n",
        "    # axs[1].hist(x, bins=n_bins)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxG3BkzlZ4s4"
      },
      "source": [
        "def prediction():\n",
        "    predicted_hz = []\n",
        "    true_hz = []\n",
        "    for inp, outp in dataset_test:\n",
        "        predicted = model.predict(inp)\n",
        "        true_hz.append(outp)\n",
        "        predicted = np.squeeze(predicted)\n",
        "        predicted_hz.append(predicted)\n",
        "    true_hz = np.reshape(np.array(true_hz), (1, (len(true_hz) * len(true_hz[0])*len(true_hz[0][0]))))\n",
        "    true_hz = np.squeeze(true_hz)\n",
        "    predicted_hz = np.reshape(np.array(predicted_hz), (1, (len(predicted_hz) * len(predicted_hz[0])*len(predicted_hz[0][0]))))\n",
        "    predicted_hz = np.squeeze(predicted_hz)\n",
        "    diff = true_hz - predicted_hz\n",
        "    return predicted_hz, true_hz, diff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHt8u-ZYZ4s4"
      },
      "source": [
        "predicted_hz, true_hz, diff = prediction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBTcNH1nZ4s4"
      },
      "source": [
        "print(len(predicted_hz), len(true_hz))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SbHSuEOZ4s5"
      },
      "source": [
        "combined = zip(true_hz, predicted_hz)\n",
        "filtered = [x for x in list(combined) if x[0] > 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-r2YsYJHZ4s5"
      },
      "source": [
        "filtered[10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khi1mJfXZ4s5"
      },
      "source": [
        "def histogram2(pitches):\n",
        "# def histogram(true_hz, predicted_hz):\n",
        "    #diff = abs(predicted_hz - true_hz)  \n",
        "    n_bins = 250\n",
        "\n",
        "    x = pitches\n",
        "\n",
        "    # fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "    # We can set the number of bins with the `bins` kwarg\n",
        "    plt.figure()\n",
        "    plt.hist(x, bins=n_bins)\n",
        "    # axs[0].hist(x, bins=n_bins)\n",
        "    # plt.xlim([-100, -50])\n",
        "    plt.ylim([0, 5000])\n",
        "    plt.xlabel(\"Errors in Hz\")\n",
        "    plt.ylabel(\"Number of Errors\")\n",
        "    plt.show()\n",
        "    # axs[1].hist(x, bins=n_bins)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0ZzOUcMZ4s5"
      },
      "source": [
        "filtered_unzipped = np.array(list(zip(*filtered)))\n",
        "diff_filtered = filtered_unzipped[0] - filtered_unzipped[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9W5ye95sZ4s5"
      },
      "source": [
        "print(len(diff_filtered))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ja4VLU2EZ4s5"
      },
      "source": [
        "true_cent = mir_eval.melody.hz2cents(filtered_unzipped[0])\n",
        "predicted_cent = mir_eval.melody.hz2cents(filtered_unzipped[1])\n",
        "std_dev_hz = np.std(diff_filtered)\n",
        "mae_hz = mean_absolute_error_hz(true_hz=filtered_unzipped[0], predicted_hz=filtered_unzipped[1])\n",
        "mean_hz = np.mean(diff_filtered)\n",
        "median_hz = np.median(diff_filtered)\n",
        "std_dev, avg = standard_deviation_hz(true_hz=filtered_unzipped[0], predicted_hz=filtered_unzipped[1])\n",
        "rpa_cent = raw_pitch_accuracy_cent(true_cent, predicted_cent)\n",
        "# histo = histogram(diff)\n",
        "quantile_05 = np.quantile(diff_filtered, 0.05)\n",
        "quantile_95 = np.quantile(diff_filtered, 0.95)\n",
        "min = np.min(diff_filtered)\n",
        "max = np.max(diff_filtered)\n",
        "\n",
        "histo_true = histogram2([x[0] - x[1] for x in filtered])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-Ux_qIwZ4s5"
      },
      "source": [
        "print(\"Stdabweichung:\", \"%.2f\" % std_dev_hz )\n",
        "print(\"Avg in Hz:\", \"%.2f\" % mean_hz)\n",
        "print(\"MAE in Hz:\", \"%.2f\" % mae_hz)\n",
        "print(\"5% Quantil:\", \"%.2f\" % quantile_05)\n",
        "print(\"95% Quantil:\", \"%.2f\" % quantile_95)\n",
        "print(\"Median in Hz:\", \"%.2f\" %median_hz)\n",
        "print(\"Max in Hz:\",\"%.2f\" % max)\n",
        "print(\"Min in Hz:\", \"%.2f\" % min)\n",
        "print(\"RPA in Cent:\", \"%.2f\" % rpa_cent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4jmWPZrZ4s5"
      },
      "source": [
        "print(true_cent[5000], predicted_cent[5000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJOmt3Xb6GXu"
      },
      "source": [
        "# Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ay1l6VuCUgW"
      },
      "source": [
        "i = 5\n",
        "z = predicted[i]\n",
        "y = outp[i]\n",
        "plt.figure()\n",
        "plt.plot(z)\n",
        "plt.plot(y)\n",
        "plt.plot(np.argmax(z),np.max(z),'x')\n",
        "plt.plot(np.argmax(y),np.max(y),'x')\n",
        "plt.ylim([0, 1.1])\n",
        "plt.text(np.argmax(z)+10,np.max(z),f'max={np.max(z):.1f} @ bin {np.argmax(z)}')\n",
        "plt.text(np.argmax(y)+10,np.max(y),f'max={np.max(y):.1f} @ bin {np.argmax(y)}')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh5ENeMKC4rn"
      },
      "source": [
        "print(to_weighted_average_cents(predicted[20]))\n",
        "print(to_local_average_cents(predicted[20]))\n",
        "print(true_cents[20])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax2vFI_vEvUP"
      },
      "source": [
        "print(outp[28][97])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyoW1qrOBAUC"
      },
      "source": [
        "z = outp[1]\n",
        "plt.figure()\n",
        "plt.plot(z)\n",
        "plt.plot(np.argmax(z),np.max(z),'x')\n",
        "plt.text(np.argmax(z)+10,np.max(z),f'max={np.max(z):.1f} @ bin {np.argmax(z)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m4HSqqMyrCb"
      },
      "source": [
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUPseECx5KEm"
      },
      "source": [
        "hz = mir_eval.melody.hz2cents(np.array([33]))\n",
        "hz"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
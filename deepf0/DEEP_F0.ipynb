{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEEP-F0.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOWV6H2DuGBRh5LfMidIvc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolfisberg/zhaw-ba-online/blob/main/deepf0/DEEP_F0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU5ZvlGglGDd"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7h2rENnSN3W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1516109-a9c9-4295-c295-3c12b562d1ee"
      },
      "source": [
        "!pip install mir_eval"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mir_eval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/fe/be4f7a59ed71938e21e89f23afe93eea0d39eb3e77f83754a12028cf1a68/mir_eval-0.6.tar.gz (87kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 16.0MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20kB 22.0MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 26.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40kB 22.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 51kB 17.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 61kB 19.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 16.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 81kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n",
            "Building wheels for collected packages: mir-eval\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.6-cp37-none-any.whl size=96515 sha256=567d6ccccb5d9c64971079954e9e7428568af61b2a833ca2ef2c12432f366e2f\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/ce/30/730fa72addf275e49d90683b01b3613048b4be3bf7ff8eb6ec\n",
            "Successfully built mir-eval\n",
            "Installing collected packages: mir-eval\n",
            "Successfully installed mir-eval-0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q42BY8BPSoL",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "851a1174-ebec-4b38-f083-70267ee0d076"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.interpolate\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import datetime\n",
        "import mir_eval\n",
        "import math\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8nh41ellB7K"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWZIc9-WSItM",
        "collapsed": true
      },
      "source": [
        "# Audio\n",
        "SNR_RANGE = (-5.0,20.0) #dB\n",
        "FRAME_LENGTH = 1024\n",
        "FRAME_STEP = 512\n",
        "MIN_RAND_GAIN = 0.05\n",
        "MAX_RAND_GAIN = 1.1\n",
        "SAMPLE_LENGTH = 3 #shorter than shortest noise/speech sample\n",
        "FS = 16000\n",
        "PITCH_SAMPLING_TIME = 0.01 # s\n",
        "PITCH_FRAME_LENGTH = 0.032 # s\n",
        "\n",
        "\n",
        "# Data\n",
        "BATCH_SIZE = 32\n",
        "NUM_FRAMES = 1 + (FS * SAMPLE_LENGTH - FRAME_LENGTH) // FRAME_STEP\n",
        "# NUM_FRAMES = 1\n",
        "\n",
        "# Training\n",
        "STEPS_PER_EPOCH = 500\n",
        "EPOCHS = 100\n",
        "VALIDATION_STEPS = 5\n",
        "\n",
        "\n",
        "# Directories\n",
        "_DATA_DIR = os.path.join('/content/drive/MyDrive/BA_2021/')\n",
        "_TFRECORDS_DIR = os.path.join(_DATA_DIR, 'tfrecords')\n",
        "\n",
        "SPEECH_DATA_TR_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'tr')\n",
        "NOISE_DATA_TR_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'tr')\n",
        "SPEECH_DATA_CV_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'cv')\n",
        "NOISE_DATA_CV_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'cv')\n",
        "SPEECH_DATA_TT_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'tt')\n",
        "NOISE_DATA_TT_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'tt')\n",
        "\n",
        "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "\n",
        "# Misc\n",
        "SEED = 2\n",
        "\n",
        "\n",
        "# Parsing\n",
        "PARSING_CONFIG_NOISE = {\n",
        "    'data': tf.io.VarLenFeature(tf.string),\n",
        "    'data_sampling_rate': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_num_channels': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_width': tf.io.VarLenFeature(tf.int64),\n",
        "}\n",
        "\n",
        "PARSING_CONFIG_SPEECH = {\n",
        "    'data': tf.io.VarLenFeature(tf.string),\n",
        "    'data_sampling_rate': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_num_channels': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_width': tf.io.VarLenFeature(tf.int64),\n",
        "    'pitch': tf.io.VarLenFeature(tf.float32),\n",
        "    'pitch_confidence': tf.io.VarLenFeature(tf.float32),\n",
        "}\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DQaQ8neunsZ"
      },
      "source": [
        "print(NOISE_DATA_TR_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-kwHYrpmCgl"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmb9w4ACwoUi"
      },
      "source": [
        "## Copy Data to Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYKlRsmDwsKM"
      },
      "source": [
        "DATA_DIR_LOCAL = '/content/data'\n",
        "\n",
        "if not os.path.exists(DATA_DIR_LOCAL):\n",
        "    os.mkdir(DATA_DIR_LOCAL)\n",
        "    \n",
        "    RECORD_DIR_LOCAL = os.path.join(DATA_DIR_LOCAL, 'tfrecords')\n",
        "    shutil.copytree(_TFRECORDS_DIR, RECORD_DIR_LOCAL)\n",
        "\n",
        "\n",
        "_TFRECORDS_DIR = os.path.join(DATA_DIR_LOCAL, 'tfrecords')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awsl19RfyOii"
      },
      "source": [
        "print(_TFRECORDS_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlkFt3Nvsqn-"
      },
      "source": [
        "## Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhwJchGumFSo"
      },
      "source": [
        "def _parse_noise_record(serialized_example):\n",
        "    parsed_features = tf.io.parse_single_example(serialized_example, features=PARSING_CONFIG_NOISE)\n",
        "    decoded_features = {\n",
        "        \"data_num_channels\": tf.cast(parsed_features[\"data_num_channels\"].values[0], tf.int32),\n",
        "        \"data_sampling_rate\": tf.cast(parsed_features[\"data_sampling_rate\"].values[0], tf.int32),\n",
        "        \"data_width\": tf.cast(parsed_features[\"data_width\"].values[0], tf.int32),\n",
        "    }\n",
        "    data = tf.io.decode_raw(parsed_features['data'].values[0], tf.int16)\n",
        "    decoded_features.update({\"data\": data})\n",
        "    return decoded_features\n",
        "\n",
        "\n",
        "def _parse_speech_record(serialized_example):\n",
        "    parsed_features = tf.io.parse_single_example(serialized_example, features=PARSING_CONFIG_SPEECH)\n",
        "    decoded_features = {\n",
        "        \"data_num_channels\": tf.cast(parsed_features[\"data_num_channels\"].values[0], tf.int32),\n",
        "        \"data_sampling_rate\": tf.cast(parsed_features[\"data_sampling_rate\"].values[0], tf.int32),\n",
        "        \"data_width\": tf.cast(parsed_features[\"data_width\"].values[0], tf.int32),\n",
        "        \"pitch\": tf.cast(parsed_features['pitch'].values, tf.float32),\n",
        "        \"pitch_confidence\": tf.cast(parsed_features['pitch_confidence'].values, tf.float32),\n",
        "    }\n",
        "    data = tf.io.decode_raw(parsed_features['data'].values[0], tf.int16)\n",
        "    decoded_features.update({\"data\": data})\n",
        "    return decoded_features\n",
        "\n",
        "\n",
        "def _mix_noisy_speech(speech, noise):\n",
        "    speech_pow = tf.math.reduce_euclidean_norm(speech)\n",
        "    noise_pow = tf.math.reduce_euclidean_norm(noise)\n",
        "\n",
        "    min_SNR = SNR_RANGE[0]\n",
        "    max_SNR = SNR_RANGE[1]\n",
        "    snr_current = 20.0*tf.math.log(speech_pow/noise_pow)/tf.math.log(10.0)\n",
        "    snr_target = tf.random.uniform((),minval=min_SNR,maxval=max_SNR)\n",
        "\n",
        "    noise = noise * tf.math.pow(10.0,(snr_current-snr_target)/20.0)\n",
        "    noisy_speech = speech+noise\n",
        "\n",
        "    return speech, noise, noisy_speech\n",
        "\n",
        "\n",
        "def _interpolate_pitch(pitch,t):\n",
        "    pitches = pitch.numpy()\n",
        "    t = t.numpy()\n",
        "    t_pitch = np.arange(0, len(pitch)) * PITCH_SAMPLING_TIME + PITCH_FRAME_LENGTH / 2\n",
        "    f = scipy.interpolate.interp1d(t_pitch, pitch, 'nearest')\n",
        "    return f(t).astype(np.float32)\n",
        "\n",
        "def convert_hz_to_cent(f,fref=10.0):\n",
        "    return mir_eval.melody.hz2cents(np.array(f), fref)\n",
        "\n",
        "def calc_bin(freq_cent, cents_per_bin = 20, lower_bound_freq=32.7):  \n",
        "    freq_cent = np.squeeze(freq_cent)\n",
        "    #freq_cent = np.reshape(freq_cent, (1, freq_cent[0]*freq_cent[1]))\n",
        "    lower_bound_freq_cent = mir_eval.melody.hz2cents(np.array([lower_bound_freq]))\n",
        "    bin = (freq_cent - lower_bound_freq_cent) / np.array([cents_per_bin])\n",
        "    #print(np.clip(bin, 0, 359))\n",
        "    return np.clip(bin, 0, 359)\n",
        "    #return min(359, max(0, bin))\n",
        "\n",
        "def calc_y(f_groundtruth, n_bins = 360):\n",
        "    c_true = calc_bin(f_groundtruth)\n",
        "    return create_bin_vector(c_true)\n",
        "\n",
        "def create_bin_vector(c_true):\n",
        "    cis = np.arange(360)\n",
        "    # cis = np.tile(cis, (len(c_true), 1))\n",
        "    y = [gaussian_blur(cis, i) for i in c_true]\n",
        "    return np.squeeze(y)\n",
        "    \n",
        "def gaussian_blur(ci, ctrue):\n",
        "    return np.exp(-(ci-ctrue)**2/(2.0*25.0**2))\n",
        "\n",
        "@tf.function\n",
        "def _interpolate_pitch_tf(pitch,t):\n",
        "    y = tf.py_function(_interpolate_pitch,[pitch,t], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "@tf.function\n",
        "def _convert_hz_to_cent(pitch):\n",
        "    y = tf.py_function(convert_hz_to_cent,[pitch], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "@tf.function\n",
        "def _calc_y(pitch_cents):\n",
        "    y = tf.py_function(calc_y,[pitch_cents], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "def _calc_features(speech_data, noise_data):\n",
        "    speech = tf.squeeze(tf.cast(speech_data[\"data\"], tf.float32))\n",
        "    noise = tf.squeeze(tf.cast(noise_data[\"data\"], tf.float32))\n",
        "    speech = speech / tf.int16.max\n",
        "    noise = noise / tf.int16.max\n",
        "\n",
        "    random_start_idx = int(tf.round(tf.random.uniform([], maxval=(\n",
        "             tf.cast(len(noise), tf.float32) - SAMPLE_LENGTH * FS - PITCH_SAMPLING_TIME))))\n",
        "    noise = noise[random_start_idx:random_start_idx + SAMPLE_LENGTH * FS]\n",
        "\n",
        "    random_start_idx = int(tf.round(tf.random.uniform([], minval=161, maxval=(\n",
        "            tf.cast(len(speech), tf.float32) - SAMPLE_LENGTH * FS - 161))))\n",
        "    speech = speech[random_start_idx:random_start_idx + SAMPLE_LENGTH * FS]   \n",
        "\n",
        "    #SNR_range = SNR_RANGE\n",
        "    frame_length = FRAME_LENGTH\n",
        "    frame_step = FRAME_STEP\n",
        "    speech, noise, noisy = _mix_noisy_speech(speech, noise)\n",
        "\n",
        "    random_gain = tf.math.exp(\n",
        "        tf.random.uniform([], minval=tf.math.log(MIN_RAND_GAIN), maxval=tf.math.log(MAX_RAND_GAIN)))\n",
        "    noisy = random_gain * noisy\n",
        "\n",
        "    noisy_frames = tf.signal.frame(noisy, frame_length, frame_step)\n",
        "    speech_frames = tf.signal.frame(speech, frame_length, frame_step)\n",
        "    noisy_frames = tf.squeeze(noisy_frames)\n",
        "    speech_frames = tf.squeeze(speech_frames)\n",
        "    #noisy_stft = tf.signal.stft(noisy,frame_length,frame_step)\n",
        "    # frame_times = random_start_idx / FS + tf.range(0, NUM_FRAMES) * frame_step / FS + frame_length / FS\n",
        "    frame_times = random_start_idx / FS + tf.range(0, NUM_FRAMES) * frame_step / FS + frame_length / FS\n",
        "    \n",
        "    pitch = tf.squeeze(speech_data[\"pitch\"])    \n",
        "    pitch_confidence = tf.squeeze(speech_data[\"pitch_confidence\"])\n",
        "    #pitch = tf.where(pitch_confidence>config['pitch_confidence_threshold'],pitch,0)\n",
        "    pitch_interpolated = _interpolate_pitch_tf(pitch, frame_times)\n",
        "    pitch_interpolated_cents = _convert_hz_to_cent(pitch_interpolated)\n",
        "    pitch_bins = _calc_y(pitch_interpolated_cents)\n",
        "    return noisy_frames, pitch_bins"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPVV-n86kqJb"
      },
      "source": [
        "a = np.random.randn(184,1)\n",
        "mir_eval.melody.hz2cents(np.squeeze(a))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0TKt5eSs0SF"
      },
      "source": [
        "## Provide Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiU-wMWPs2dZ"
      },
      "source": [
        "def get_training_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_TR_DIR, file) for file in os.listdir(SPEECH_DATA_TR_DIR)])\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_TR_DIR, file) for file in os.listdir(NOISE_DATA_TR_DIR)])\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "    return dataset_features\n",
        "\n",
        "\n",
        "def get_validation_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_CV_DIR, file) for file in os.listdir(SPEECH_DATA_CV_DIR)])\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_CV_DIR, file) for file in os.listdir(NOISE_DATA_CV_DIR)])\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset_features\n",
        "\n",
        "\n",
        "def get_test_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_TT_DIR, file) for file in os.listdir(SPEECH_DATA_TT_DIR)])\n",
        "    # speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(10).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_TT_DIR, file) for file in os.listdir(NOISE_DATA_TT_DIR)])\n",
        "    # noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(10).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset_features"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdIXYFTDoN1j"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLnYza9woPzS"
      },
      "source": [
        "## DEEP-F0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmKx4gLkKjwQ"
      },
      "source": [
        "## DEEP-FO without time component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPzG257AP4uR"
      },
      "source": [
        "MODEL_USED = 'deepf0'\n",
        "LOG_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'logs', TIMESTAMP)\n",
        "if not os.path.exists(LOG_DIR):\n",
        "    os.makedirs(LOG_DIR)\n",
        "CHECKPOINT_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'checkpoints', TIMESTAMP)\n",
        "if not os.path.exists(CHECKPOINT_DIR):\n",
        "    os.makedirs(CHECKPOINT_DIR)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPygi-4sKooq"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Reshape, Conv2D, BatchNormalization\n",
        "from tensorflow.keras.layers import MaxPool2D, Dropout, Permute, Flatten, Dense, Add, ReLU\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def resblock(x, filters, kernelsize, dilationrate):\n",
        "    fx = Conv2D(filters, (64, 1), padding='same',\n",
        "                   activation='relu', name=\"conv%d\" % dilationrate)(x)\n",
        "    fx = BatchNormalization()(fx)\n",
        "    fx = Conv2D(filters, 1, padding='same')(fx)\n",
        "    out = Add()([x,fx])\n",
        "    out = ReLU()(out)\n",
        "    return out\n",
        "\n",
        "def get_model_crepe():\n",
        "    layers = 1\n",
        "    filters = 128\n",
        "    width = 512\n",
        "    strides = (16, 1)\n",
        "    dilation_rate_list = [1, 2, 4, 8]\n",
        "\n",
        "    x = Input(shape=(1024,), name='input', dtype='float32')\n",
        "    y = Reshape(target_shape=(1024, 1, 1), name='input-reshape')(x)\n",
        "\n",
        "\n",
        "    y = Conv2D(filters, (width, 1), strides=strides, padding='same',\n",
        "                activation='relu')(y)\n",
        "    for i in range(len(dilation_rate_list)):\n",
        "        dilation_rate = dilation_rate_list[i]\n",
        "        y = resblock(y, 128, 64, dilation_rate)\n",
        "    y = BatchNormalization(name=\"conv1d-BN\")(y)\n",
        "    y = MaxPool2D(pool_size=(2, 1), strides=None, padding='valid',\n",
        "                        name=\"conv1d-maxpool\")(y)\n",
        "    y = Dropout(0.25, name=\"convd-dropout\")(y)\n",
        "\n",
        "    y = Permute((2, 1, 3), name=\"transpose\")(y)\n",
        "    y = Flatten(name=\"flatten\")(y)\n",
        "    y = Dense(360, activation='sigmoid', name=\"classifier\")(y)\n",
        "   \n",
        "\n",
        "    model = Model(inputs=x, outputs=y)\n",
        "    model.compile('adam', 'binary_crossentropy', metrics=['mse', 'mae'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-SpsYhaCNV"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g6YW7mUtA64"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uU1pyCDPm8C7"
      },
      "source": [
        "dataset_training = get_training_data()\n",
        "dataset_validation = get_validation_data()\n",
        "dataset_test = get_test_data()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dzEiCs_tDcJ"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poP21a6TnLHO"
      },
      "source": [
        "model = get_model_crepe()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "33_wEPK8nNfC"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9FxwYbUXD3_"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbVgnmcitIjt"
      },
      "source": [
        "## Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHZ4eMqMnchd",
        "collapsed": true
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/BA_2021/crepe/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn0JRWrccNJH"
      },
      "source": [
        "# JUST USE IF CONTINUING TRAINING\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/BA_2021/crepe/checkpoints/20210427-145400'\n",
        "LOGDIR = '/content/drive/MyDrive/BA_2021/crepe/logs/20210427-145400'\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/crepe/checkpoints', '20210427-145400', '50-2063.93.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OMUc5cRQnSNQ"
      },
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(LOG_DIR, histogram_freq=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(CHECKPOINT_DIR,'{epoch:02d}-{val_loss:.2f}.hdf5'))\n",
        "\n",
        "callbacks = [checkpoint, tensorboard_callback]\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    dataset_training,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    epochs=50,\n",
        "    # initial_epoch=30,\n",
        "    verbose = 1,\n",
        "    validation_data = dataset_validation,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks = callbacks)\n",
        "    \n",
        "loss = model.evaluate(dataset_test, steps=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sg0cbO1z2DTj"
      },
      "source": [
        "inp, outp = next(iter(dataset_test))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgj1DGAaAo0v"
      },
      "source": [
        "pred = model.predict(inp)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxGCoAFhasse",
        "outputId": "b5ff515e-3eff-4eac-a5f7-1ffbb6d7bc72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.plot(pred[0], 'b')\n",
        "plt.plot(outp[0], 'g')\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVozVO6-vtO3"
      },
      "source": [
        "# Prediction Metrics Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-XJKS-W4Q2D"
      },
      "source": [
        "classifier_lowest_hz = 32.70\n",
        "classifier_lowest_cent = mir_eval.melody.hz2cents(np.array([classifier_lowest_hz]))[0]\n",
        "classifier_cents_per_bin = 20\n",
        "classifier_octaves = 6\n",
        "classifier_total_bins = int((1200 / classifier_cents_per_bin) * classifier_octaves)\n",
        "classifier_cents = np.linspace(0, (classifier_total_bins - 1) * classifier_cents_per_bin, classifier_total_bins) + classifier_lowest_cent\n",
        "\n",
        "def to_weighted_average_cents(label):\n",
        "    if label.ndim == 1:\n",
        "        productsum = np.sum(label * classifier_cents)\n",
        "        weightsum = np.sum(label)\n",
        "        return productsum / weightsum\n",
        "    if label.ndim == 2:\n",
        "        productsum = np.dot(label, classifier_cents)\n",
        "        weightsum = np.sum(label, axis=1)\n",
        "        return productsum / weightsum\n",
        "    raise Exception(\"label should be either 1d or 2d ndarray\")\n",
        "\n",
        "def to_local_average_cents(salience, center=None):\n",
        "    \"\"\"\n",
        "    find the weighted average cents near the argmax bin\n",
        "    \"\"\"\n",
        "    if not hasattr(to_local_average_cents, 'cents_mapping'):\n",
        "        # the bin number-to-cents mapping\n",
        "        to_local_average_cents.cents_mapping = (\n",
        "                np.linspace(0, 7180, 360) + 1997.3794084376191)\n",
        "\n",
        "    if salience.ndim == 1:\n",
        "        if center is None:\n",
        "            center = int(np.argmax(salience))\n",
        "        start = max(0, center - 4)\n",
        "        end = min(len(salience), center + 5)\n",
        "        salience = salience[start:end]\n",
        "        product_sum = np.sum(\n",
        "            salience * to_local_average_cents.cents_mapping[start:end])\n",
        "        weight_sum = np.sum(salience)\n",
        "        return product_sum / weight_sum\n",
        "    if salience.ndim == 2:\n",
        "        return np.array([to_local_average_cents(salience[i, :]) for i in\n",
        "                         range(salience.shape[0])])\n",
        "\n",
        "    raise Exception(\"label should be either 1d or 2d ndarray\")\n",
        "\n",
        "def convert_cent_to_hz(c,fref=10.0):\n",
        "    return fref*2**(c/1200.0)\n",
        "\n",
        "def raw_pitch_accuracy_cent(true_cents, predicted_cents, cent_tolerence=50):\n",
        "    counter_true = 0\n",
        "    counter_false = 0\n",
        "    for i in range(len(true_cents)):\n",
        "        if abs(predicted_cents[i] - true_cents[i]) <= 50.0:\n",
        "            counter_true += 1\n",
        "        else:\n",
        "            counter_false += 1\n",
        "    if counter_true > 0:\n",
        "        result = counter_true / (counter_true + counter_false) * 100\n",
        "    else:\n",
        "        result = 0\n",
        "    return result\n",
        "\n",
        "def raw_pitch_accuracy_hz(true_hz, predicted_hz):\n",
        "    counter_true = 0\n",
        "    counter_false = 0\n",
        "    for i in range(len(true_hz)):\n",
        "        if abs(predicted_hz[i] - true_hz[i]) <= (true_hz[i] * 0.02):\n",
        "            counter_true += 1\n",
        "        else:\n",
        "            counter_false += 1\n",
        "    if counter_true > 0:\n",
        "        result = counter_true / (counter_true + counter_false) * 100\n",
        "    else:\n",
        "        result = 0\n",
        "    return result\n",
        "\n",
        "def standard_deviation_cent(true_cents, predicted_cents):\n",
        "    diff = abs(predicted_cents - true_cents)\n",
        "    avg = np.mean(diff)\n",
        "    diff = np.square(diff - avg)\n",
        "    sum = np.sum(diff)\n",
        "    std_dev = np.sqrt((sum / (len(diff)-1)))\n",
        "    return std_dev\n",
        "\n",
        "def standard_deviation_hz(true_hz, predicted_hz):\n",
        "    diff = abs(predicted_hz - true_hz)\n",
        "    avg = np.mean(diff)\n",
        "    diff = np.square(diff - avg)\n",
        "    sum = np.sum(diff)\n",
        "    std_dev = np.sqrt((sum / (len(diff)-1)))\n",
        "    return std_dev\n",
        "\n",
        "def mean_absolute_error_cent(true_cents, predicted_cents):\n",
        "    diff = abs(predicted_cents - true_cents)\n",
        "    mae = np.mean(diff)\n",
        "    return mae\n",
        "\n",
        "def mean_absolute_error_hz(true_hz, predicted_hz):\n",
        "    diff = abs(predicted_hz - true_hz)\n",
        "    mae = np.mean(diff)\n",
        "    return mae"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O2yL6xTM4iD"
      },
      "source": [
        "def histogram(diff):\n",
        "# def histogram(true_hz, predicted_hz):\n",
        "    #diff = abs(predicted_hz - true_hz)  \n",
        "    n_bins = 250\n",
        "\n",
        "    x = diff\n",
        "    y = true_hz\n",
        "\n",
        "    # fig, axs = plt.subplots(1, 2, sharey=True, tight_layout=True)\n",
        "\n",
        "    # We can set the number of bins with the `bins` kwarg\n",
        "    plt.figure()\n",
        "    plt.hist(x, bins=n_bins)\n",
        "    # axs[0].hist(x, bins=n_bins)\n",
        "    #plt.xlim([-200, 200])\n",
        "    plt.ylim([0, 5000])\n",
        "    plt.xlabel(\"Error in Hertz\")\n",
        "    plt.ylabel(\"Number of Errors\")\n",
        "    plt.show()\n",
        "    # axs[1].hist(x, bins=n_bins)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnoXGQL06WdR"
      },
      "source": [
        "def prediction():\n",
        "    predicted_c = []\n",
        "    true_c = []\n",
        "    for inp, outp in dataset_test:\n",
        "        predicted = model.predict(inp)\n",
        "        true_cents = to_local_average_cents(outp)\n",
        "        true_c.append(true_cents)\n",
        "        predicted_cents = to_local_average_cents(np.squeeze(predicted))\n",
        "        predicted_c.append(predicted_cents)\n",
        "\n",
        "    true_c = np.reshape(np.array(true_c), (1, (len(true_c)*len(true_c[0]))))\n",
        "    true_c = np.squeeze(true_c)\n",
        "    true_hz = convert_cent_to_hz(true_c)\n",
        "    predicted_c = np.reshape(np.array(predicted_c), (1, (len(predicted_c)*len(predicted_c[0]))))\n",
        "    predicted_c = np.squeeze(predicted_c)\n",
        "    predicted_hz = convert_cent_to_hz(predicted_c)\n",
        "    diff = true_hz - predicted_hz\n",
        "    return predicted_hz, true_hz, true_c, predicted_c, diff"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msEYwMhNddcK"
      },
      "source": [
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/deepf0/checkpoints', '20210428-212705', '50-0.18.hdf5'))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh3HIl3f7ONH"
      },
      "source": [
        "predicted_hz, true_hz, true_cent, predicted_cent, diff = prediction()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcrLxYRs5V73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "493e70ba-9575-4280-8cc6-ac159f9880ef"
      },
      "source": [
        "print(predicted_hz.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(429824,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUs_jXsA-8h5"
      },
      "source": [
        "# diff = np.abs(diff)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhTJzY9A8b7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "f506cf39-c5e7-487c-8140-2d1645aa8ca6"
      },
      "source": [
        "std_dev_hz = np.std(diff)\n",
        "mae_hz = mean_absolute_error_hz(true_hz, predicted_hz)\n",
        "mean_hz = np.mean(diff)\n",
        "median_hz = np.median(diff)\n",
        "# std_dev, avg = standard_deviation_hz(true_hz, predicted_hz)\n",
        "rpa_cent = raw_pitch_accuracy_cent(true_cent, predicted_cent)\n",
        "histo = histogram(diff)\n",
        "quantile_05 = np.quantile(diff, 0.05)\n",
        "quantile_95 = np.quantile(diff, 0.95)\n",
        "min = np.min(diff)\n",
        "max = np.max(diff)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCTj31ObAZ4O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36534ca6-7025-43ab-808f-0b7c950ddd8f"
      },
      "source": [
        "print(\"Stdabweichung:\", \"%.2f\" % std_dev_hz )\n",
        "print(\"Avg in Hz:\", \"%.2f\" % mean_hz)\n",
        "print(\"MAE in Hz:\", \"%.2f\" % mae_hz)\n",
        "print(\"5% Quantil:\", \"%.2f\" % quantile_05)\n",
        "print(\"95% Quantil:\", \"%.2f\" % quantile_95)\n",
        "print(\"Median in Hz:\", \"%.2f\" %median_hz)\n",
        "print(\"Max in Hz:\",\"%.2f\" % max)\n",
        "print(\"Min in Hz:\", \"%.2f\" % min)\n",
        "print(\"RPA in Cent:\", \"%.2f\" % rpa_cent)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stdabweichung: 39.89\n",
            "Avg in Hz: 2.07\n",
            "MAE in Hz: 13.21\n",
            "5% Quantil: -8.38\n",
            "95% Quantil: 68.99\n",
            "Median in Hz: -0.00\n",
            "Max in Hz: 322.11\n",
            "Min in Hz: -265.66\n",
            "RPA in Cent: 80.31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tfibfpLa5nv"
      },
      "source": [
        "def prediction_metrics():\n",
        "    predicted_c = []\n",
        "    true_c = []\n",
        "    \n",
        "    for inp, outp in dataset_test:\n",
        "        predicted = model.predict(inp)\n",
        "        true_cents = to_local_average_cents(outp)\n",
        "        true_c.append(true_cents)\n",
        "        predicted_cents = to_local_average_cents(np.squeeze(predicted))\n",
        "        predicted_c.append(predicted_cents)\n",
        "    \n",
        "    true_c = np.reshape(np.array(true_c), (1, (len(true_c)*len(true_c[0]))))\n",
        "    true_c = np.squeeze(true_c)\n",
        "    true_hz = convert_cent_to_hz(true_c)\n",
        "    predicted_c = np.reshape(np.array(predicted_c), (1, (len(predicted_c)*len(predicted_c[0]))))\n",
        "    predicted_c = np.squeeze(predicted_c)\n",
        "    predicted_hz = convert_cent_to_hz(predicted_c)\n",
        "    \n",
        "    # Raw Pitch Accuracy\n",
        "    rpa_cent = raw_pitch_accuracy_cent(true_c, predicted_c)\n",
        "    rpa_hz = raw_pitch_accuracy_hz(true_hz, predicted_hz)\n",
        "\n",
        "    # Standard Deviation\n",
        "    std_dev_cent = standard_deviation_cent(true_c, predicted_c)\n",
        "    std_dev_hz = standard_deviation_hz(true_hz, predicted_hz)\n",
        "\n",
        "    # Mean Absolute Error\n",
        "    mae_cent = mean_absolute_error_cent(true_c, predicted_c)\n",
        "    mae_hz = mean_absolute_error_hz(true_hz, predicted_hz)\n",
        "    return rpa_cent, rpa_hz, std_dev_cent, std_dev_hz, mae_cent, mae_hz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOvlZw9tbnl7"
      },
      "source": [
        "pred = prediction_metrics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIcO858ubuTv"
      },
      "source": [
        "print(pred[0], pred[1], pred[2], pred[3], pred[4], pred[5])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPA7rTSjMgoc"
      },
      "source": [
        "inp, outp = next(iter(dataset_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKZMk4CsCKuc"
      },
      "source": [
        "cents = to_weighted_average_cents(outp)\n",
        "predicted = model.predict(inp, steps=1)\n",
        "predicted = np.squeeze(predicted)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
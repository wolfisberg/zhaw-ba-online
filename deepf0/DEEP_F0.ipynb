{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEEP-F0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolfisberg/zhaw-ba-online/blob/main/deepf0/DEEP_F0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU5ZvlGglGDd"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q42BY8BPSoL",
        "collapsed": true,
        "outputId": "5d53dafe-4f77-4adc-e039-12e3c5859224",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mir_eval\n",
        "!pip install rt_pie\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.interpolate\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import datetime\n",
        "import mir_eval\n",
        "import math\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mir_eval in /usr/local/lib/python3.7/dist-packages (0.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n",
            "Requirement already satisfied: rt_pie in /usr/local/lib/python3.7/dist-packages (0.1.8)\n",
            "Requirement already satisfied: mir_eval<0.7,>=0.6 in /usr/local/lib/python3.7/dist-packages (from rt_pie) (0.6)\n",
            "Requirement already satisfied: numpy<1.20,>=1.19 in /usr/local/lib/python3.7/dist-packages (from rt_pie) (1.19.5)\n",
            "Requirement already satisfied: tensorflow<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from rt_pie) (2.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval<0.7,>=0.6->rt_pie) (0.16.0)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval<0.7,>=0.6->rt_pie) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval<0.7,>=0.6->rt_pie) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (2.4.1)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (0.2.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (1.1.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (2.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (1.1.2)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (3.3.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (1.32.0)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (2.10.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (0.3.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<3.0.0,>=2.4.1->rt_pie) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (2.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (1.30.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (1.8.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (4.7.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3.0.0,>=2.4.1->rt_pie) (3.4.1)\n",
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8nh41ellB7K"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWZIc9-WSItM",
        "collapsed": true
      },
      "source": [
        "# Audio\n",
        "SNR_RANGE = (-5.0,20.0) #dB\n",
        "FRAME_LENGTH = 1024\n",
        "FRAME_STEP = 512\n",
        "MIN_RAND_GAIN = 0.05\n",
        "MAX_RAND_GAIN = 1.1\n",
        "SAMPLE_LENGTH = 3 #shorter than shortest noise/speech sample\n",
        "FS = 16000\n",
        "PITCH_SAMPLING_TIME = 0.01 # s\n",
        "PITCH_FRAME_LENGTH = 0.032 # s\n",
        "\n",
        "\n",
        "# Data\n",
        "BATCH_SIZE = 32\n",
        "NUM_FRAMES = 1 + (FS * SAMPLE_LENGTH - FRAME_LENGTH) // FRAME_STEP\n",
        "# NUM_FRAMES = 1\n",
        "\n",
        "# Training\n",
        "STEPS_PER_EPOCH = 500\n",
        "EPOCHS = 100\n",
        "VALIDATION_STEPS = 5\n",
        "\n",
        "\n",
        "# Directories\n",
        "_DATA_DIR = os.path.join('/content/drive/MyDrive/BA_2021/')\n",
        "_TFRECORDS_DIR = os.path.join(_DATA_DIR, 'tfrecords')\n",
        "\n",
        "SPEECH_DATA_TR_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'tr')\n",
        "NOISE_DATA_TR_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'tr')\n",
        "SPEECH_DATA_CV_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'cv')\n",
        "NOISE_DATA_CV_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'cv')\n",
        "SPEECH_DATA_TT_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'tt')\n",
        "NOISE_DATA_TT_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'tt')\n",
        "\n",
        "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "\n",
        "# Misc\n",
        "SEED = 2\n",
        "\n",
        "\n",
        "# Parsing\n",
        "PARSING_CONFIG_NOISE = {\n",
        "    'data': tf.io.VarLenFeature(tf.string),\n",
        "    'data_sampling_rate': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_num_channels': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_width': tf.io.VarLenFeature(tf.int64),\n",
        "}\n",
        "\n",
        "PARSING_CONFIG_SPEECH = {\n",
        "    'data': tf.io.VarLenFeature(tf.string),\n",
        "    'data_sampling_rate': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_num_channels': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_width': tf.io.VarLenFeature(tf.int64),\n",
        "    'pitch': tf.io.VarLenFeature(tf.float32),\n",
        "    'pitch_confidence': tf.io.VarLenFeature(tf.float32),\n",
        "}\n",
        "\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-kwHYrpmCgl"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmb9w4ACwoUi"
      },
      "source": [
        "## Copy Data to Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYKlRsmDwsKM"
      },
      "source": [
        "DATA_DIR_LOCAL = '/content/data'\n",
        "\n",
        "if not os.path.exists(DATA_DIR_LOCAL):\n",
        "    os.mkdir(DATA_DIR_LOCAL)\n",
        "    \n",
        "    RECORD_DIR_LOCAL = os.path.join(DATA_DIR_LOCAL, 'tfrecords')\n",
        "    shutil.copytree(_TFRECORDS_DIR, RECORD_DIR_LOCAL)\n",
        "\n",
        "\n",
        "_TFRECORDS_DIR = os.path.join(DATA_DIR_LOCAL, 'tfrecords')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlkFt3Nvsqn-"
      },
      "source": [
        "## Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhwJchGumFSo"
      },
      "source": [
        "def _parse_noise_record(serialized_example):\n",
        "    parsed_features = tf.io.parse_single_example(serialized_example, features=PARSING_CONFIG_NOISE)\n",
        "    decoded_features = {\n",
        "        \"data_num_channels\": tf.cast(parsed_features[\"data_num_channels\"].values[0], tf.int32),\n",
        "        \"data_sampling_rate\": tf.cast(parsed_features[\"data_sampling_rate\"].values[0], tf.int32),\n",
        "        \"data_width\": tf.cast(parsed_features[\"data_width\"].values[0], tf.int32),\n",
        "    }\n",
        "    data = tf.io.decode_raw(parsed_features['data'].values[0], tf.int16)\n",
        "    decoded_features.update({\"data\": data})\n",
        "    return decoded_features\n",
        "\n",
        "\n",
        "def _parse_speech_record(serialized_example):\n",
        "    parsed_features = tf.io.parse_single_example(serialized_example, features=PARSING_CONFIG_SPEECH)\n",
        "    decoded_features = {\n",
        "        \"data_num_channels\": tf.cast(parsed_features[\"data_num_channels\"].values[0], tf.int32),\n",
        "        \"data_sampling_rate\": tf.cast(parsed_features[\"data_sampling_rate\"].values[0], tf.int32),\n",
        "        \"data_width\": tf.cast(parsed_features[\"data_width\"].values[0], tf.int32),\n",
        "        \"pitch\": tf.cast(parsed_features['pitch'].values, tf.float32),\n",
        "        \"pitch_confidence\": tf.cast(parsed_features['pitch_confidence'].values, tf.float32),\n",
        "    }\n",
        "    data = tf.io.decode_raw(parsed_features['data'].values[0], tf.int16)\n",
        "    decoded_features.update({\"data\": data})\n",
        "    return decoded_features\n",
        "\n",
        "\n",
        "def _mix_noisy_speech(speech, noise):\n",
        "    speech_pow = tf.math.reduce_euclidean_norm(speech)\n",
        "    noise_pow = tf.math.reduce_euclidean_norm(noise)\n",
        "\n",
        "    min_SNR = SNR_RANGE[0]\n",
        "    max_SNR = SNR_RANGE[1]\n",
        "    snr_current = 20.0*tf.math.log(speech_pow/noise_pow)/tf.math.log(10.0)\n",
        "    snr_target = tf.random.uniform((),minval=min_SNR,maxval=max_SNR)\n",
        "\n",
        "    noise = noise * tf.math.pow(10.0,(snr_current-snr_target)/20.0)\n",
        "    noisy_speech = speech+noise\n",
        "\n",
        "    return speech, noise, noisy_speech\n",
        "\n",
        "\n",
        "def _interpolate_pitch(pitch,t):\n",
        "    pitches = pitch.numpy()\n",
        "    t = t.numpy()\n",
        "    t_pitch = np.arange(0, len(pitch)) * PITCH_SAMPLING_TIME + PITCH_FRAME_LENGTH / 2\n",
        "    f = scipy.interpolate.interp1d(t_pitch, pitch, 'nearest')\n",
        "    return f(t).astype(np.float32)\n",
        "\n",
        "def convert_hz_to_cent(f,fref=10.0):\n",
        "    return mir_eval.melody.hz2cents(np.array(f), fref)\n",
        "\n",
        "def calc_bin(freq_cent, cents_per_bin = 20, lower_bound_freq=32.7):  \n",
        "    freq_cent = np.squeeze(freq_cent)\n",
        "    lower_bound_freq_cent = mir_eval.melody.hz2cents(np.array([lower_bound_freq]))\n",
        "    bin = (freq_cent - lower_bound_freq_cent) / np.array([cents_per_bin])\n",
        "    return np.clip(bin, 0, 359)\n",
        "\n",
        "def calc_y(f_groundtruth, n_bins = 360):\n",
        "    c_true = calc_bin(f_groundtruth)\n",
        "    return create_bin_vector(c_true)\n",
        "\n",
        "def create_bin_vector(c_true):\n",
        "    cis = np.arange(360)\n",
        "    y = [gaussian_blur(cis, i) for i in c_true]\n",
        "    return np.squeeze(y)\n",
        "    \n",
        "def gaussian_blur(ci, ctrue):\n",
        "    return np.exp(-(ci-ctrue)**2/(2.0*25.0**2))\n",
        "\n",
        "@tf.function\n",
        "def _interpolate_pitch_tf(pitch,t):\n",
        "    y = tf.py_function(_interpolate_pitch,[pitch,t], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "@tf.function\n",
        "def _convert_hz_to_cent(pitch):\n",
        "    y = tf.py_function(convert_hz_to_cent,[pitch], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "@tf.function\n",
        "def _calc_y(pitch_cents):\n",
        "    y = tf.py_function(calc_y,[pitch_cents], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "def _calc_features(speech_data, noise_data):\n",
        "    speech = tf.squeeze(tf.cast(speech_data[\"data\"], tf.float32))\n",
        "    noise = tf.squeeze(tf.cast(noise_data[\"data\"], tf.float32))\n",
        "    speech = speech / tf.int16.max\n",
        "    noise = noise / tf.int16.max\n",
        "\n",
        "    random_start_idx = int(tf.round(tf.random.uniform([], maxval=(\n",
        "             tf.cast(len(noise), tf.float32) - SAMPLE_LENGTH * FS - PITCH_SAMPLING_TIME))))\n",
        "    noise = noise[random_start_idx:random_start_idx + SAMPLE_LENGTH * FS]\n",
        "\n",
        "    random_start_idx = int(tf.round(tf.random.uniform([], minval=161, maxval=(\n",
        "            tf.cast(len(speech), tf.float32) - SAMPLE_LENGTH * FS - 161))))\n",
        "    speech = speech[random_start_idx:random_start_idx + SAMPLE_LENGTH * FS]   \n",
        "\n",
        "    #SNR_range = SNR_RANGE\n",
        "    frame_length = FRAME_LENGTH\n",
        "    frame_step = FRAME_STEP\n",
        "    speech, noise, noisy = _mix_noisy_speech(speech, noise)\n",
        "\n",
        "    random_gain = tf.math.exp(\n",
        "        tf.random.uniform([], minval=tf.math.log(MIN_RAND_GAIN), maxval=tf.math.log(MAX_RAND_GAIN)))\n",
        "    noisy = random_gain * noisy\n",
        "\n",
        "    noisy_frames = tf.signal.frame(noisy, frame_length, frame_step)\n",
        "    speech_frames = tf.signal.frame(speech, frame_length, frame_step)\n",
        "    noisy_frames = tf.squeeze(noisy_frames)\n",
        "    speech_frames = tf.squeeze(speech_frames)\n",
        "    #noisy_stft = tf.signal.stft(noisy,frame_length,frame_step)\n",
        "    frame_times = random_start_idx / FS + tf.range(0, NUM_FRAMES) * frame_step / FS + frame_length / FS\n",
        "    \n",
        "    pitch = tf.squeeze(speech_data[\"pitch\"])    \n",
        "    pitch_confidence = tf.squeeze(speech_data[\"pitch_confidence\"])\n",
        "    #pitch = tf.where(pitch_confidence>config['pitch_confidence_threshold'],pitch,0)\n",
        "    pitch_interpolated = _interpolate_pitch_tf(pitch, frame_times)\n",
        "    pitch_interpolated_cents = _convert_hz_to_cent(pitch_interpolated)\n",
        "    pitch_bins = _calc_y(pitch_interpolated_cents)\n",
        "    return noisy_frames, pitch_bins"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0TKt5eSs0SF"
      },
      "source": [
        "## Provide Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiU-wMWPs2dZ"
      },
      "source": [
        "def get_training_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_TR_DIR, file) for file in os.listdir(SPEECH_DATA_TR_DIR)])\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_TR_DIR, file) for file in os.listdir(NOISE_DATA_TR_DIR)])\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "    return dataset_features\n",
        "\n",
        "\n",
        "def get_validation_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_CV_DIR, file) for file in os.listdir(SPEECH_DATA_CV_DIR)])\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_CV_DIR, file) for file in os.listdir(NOISE_DATA_CV_DIR)])\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset_features\n",
        "\n",
        "\n",
        "def get_test_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_TT_DIR, file) for file in os.listdir(SPEECH_DATA_TT_DIR)])\n",
        "    # speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(10).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_TT_DIR, file) for file in os.listdir(NOISE_DATA_TT_DIR)])\n",
        "    # noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(10).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset_features"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdIXYFTDoN1j"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmKx4gLkKjwQ"
      },
      "source": [
        "## DEEP-F0 without time component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPygi-4sKooq"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Reshape, Conv2D, BatchNormalization\n",
        "from tensorflow.keras.layers import AveragePooling2D, Dropout, Permute, Flatten, Dense, Add, ReLU\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def resblock(x, filters, kernelsize, dilationrate, name):\n",
        "    fx = Conv2D(filters, (kernelsize, 1), dilation_rate=(dilationrate, 1), padding='same',\n",
        "                   activation='relu', name=\"dilation-conv%d\" % name)(x)\n",
        "    fx = BatchNormalization()(fx)\n",
        "    fx = Conv2D(filters, 1, padding='same')(fx)\n",
        "    out = Add()([x,fx])\n",
        "    out = ReLU()(out)\n",
        "    return out\n",
        "\n",
        "def get_model_deepf0():\n",
        "    layers = 1\n",
        "    filters = 128\n",
        "    width = 64\n",
        "    strides = (16, 1)\n",
        "    dilation_rate = 8\n",
        "\n",
        "    x = Input(shape=(FRAME_LENGTH,), name='input', dtype='float32')\n",
        "    y = Reshape(target_shape=(FRAME_LENGTH, 1, 1), name='input-reshape')(x)\n",
        "\n",
        "\n",
        "    y = Conv2D(filters, (width, 1), strides=strides, padding='same',\n",
        "                activation='relu')(y)\n",
        "    for i in range(4):\n",
        "        y = resblock(y, filters, 64, dilation_rate, name=i)\n",
        "    y = AveragePooling2D(pool_size=(2, 1), strides=None, padding='valid',\n",
        "                        name=\"conv1d-avgpool\")(y)\n",
        "    y = Permute((2, 1, 3), name=\"transpose\")(y)\n",
        "    y = Flatten(name=\"flatten\")(y)\n",
        "    y = Dense(360, activation='sigmoid', name=\"classifier\")(y)\n",
        "   \n",
        "\n",
        "    model = Model(inputs=x, outputs=y)\n",
        "    model.compile('adam', 'binary_crossentropy', metrics=['mse', 'mae'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-SpsYhaCNV"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g6YW7mUtA64"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uU1pyCDPm8C7"
      },
      "source": [
        "dataset_training = get_training_data()\n",
        "dataset_validation = get_validation_data()\n",
        "dataset_test = get_test_data()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dzEiCs_tDcJ"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poP21a6TnLHO"
      },
      "source": [
        "model = get_model_deepf0()"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33_wEPK8nNfC",
        "outputId": "e9588bf9-b611-485e-d143-b6e0fd597ffe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input (InputLayer)              [(None, 2048)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input-reshape (Reshape)         (None, 2048, 1, 1)   0           input[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 128, 1, 128)  8320        input-reshape[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dilation-conv0 (Conv2D)         (None, 128, 1, 128)  1048704     conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 128, 1, 128)  512         dilation-conv0[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 128, 1, 128)  16512       batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, 128, 1, 128)  0           conv2d_22[0][0]                  \n",
            "                                                                 conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_16 (ReLU)                 (None, 128, 1, 128)  0           add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dilation-conv1 (Conv2D)         (None, 128, 1, 128)  1048704     re_lu_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 128, 1, 128)  512         dilation-conv1[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 128, 1, 128)  16512       batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, 128, 1, 128)  0           re_lu_16[0][0]                   \n",
            "                                                                 conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_17 (ReLU)                 (None, 128, 1, 128)  0           add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dilation-conv2 (Conv2D)         (None, 128, 1, 128)  1048704     re_lu_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 128, 1, 128)  512         dilation-conv2[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 128, 1, 128)  16512       batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, 128, 1, 128)  0           re_lu_17[0][0]                   \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_18 (ReLU)                 (None, 128, 1, 128)  0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dilation-conv3 (Conv2D)         (None, 128, 1, 128)  1048704     re_lu_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 128, 1, 128)  512         dilation-conv3[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 128, 1, 128)  16512       batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, 128, 1, 128)  0           re_lu_18[0][0]                   \n",
            "                                                                 conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_19 (ReLU)                 (None, 128, 1, 128)  0           add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv1d-avgpool (AveragePooling2 (None, 64, 1, 128)   0           re_lu_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "transpose (Permute)             (None, 1, 64, 128)   0           conv1d-avgpool[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 8192)         0           transpose[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "classifier (Dense)              (None, 360)          2949480     flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 7,220,712\n",
            "Trainable params: 7,219,688\n",
            "Non-trainable params: 1,024\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9FxwYbUXD3_"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbVgnmcitIjt"
      },
      "source": [
        "## Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHZ4eMqMnchd",
        "collapsed": true
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/BA_2021/deepf0/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPzG257AP4uR"
      },
      "source": [
        "# USE IF IT IS INITIAL TRAINING\n",
        "\n",
        "MODEL_USED = 'deepf0'\n",
        "LOG_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'logs', TIMESTAMP + '_2048_1024_100_Epochs')\n",
        "if not os.path.exists(LOG_DIR):\n",
        "    os.makedirs(LOG_DIR)\n",
        "CHECKPOINT_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'checkpoints', TIMESTAMP + '_2048_1024_100_Epochs')\n",
        "if not os.path.exists(CHECKPOINT_DIR):\n",
        "    os.makedirs(CHECKPOINT_DIR)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn0JRWrccNJH"
      },
      "source": [
        "# JUST USE IF CONTINUING TRAINING\n",
        "\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/BA_2021/crepe/checkpoints/20210427-145400'\n",
        "LOGDIR = '/content/drive/MyDrive/BA_2021/crepe/logs/20210427-145400'\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/crepe/checkpoints', '20210427-145400', '50-2063.93.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OMUc5cRQnSNQ",
        "outputId": "4e969763-b402-4240-b049-4210f2cbafff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(LOG_DIR, histogram_freq=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(CHECKPOINT_DIR,'{epoch:02d}-{val_loss:.2f}.hdf5'))\n",
        "early_stopping =  tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=32, mode='min')\n",
        "\n",
        "callbacks = [checkpoint, tensorboard_callback, early_stopping]\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    dataset_training,\n",
        "    steps_per_epoch=500,\n",
        "    epochs=100,\n",
        "    # initial_epoch=30,\n",
        "    verbose = 1,\n",
        "    validation_data = dataset_validation,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks = callbacks)\n",
        "    \n",
        "loss = model.evaluate(dataset_test, steps=70)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 32s 54ms/step - loss: 0.2359 - mse: 0.0358 - mae: 0.0920 - val_loss: 0.2277 - val_mse: 0.0369 - val_mae: 0.1098\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.2053 - mse: 0.0288 - mae: 0.0781 - val_loss: 0.2091 - val_mse: 0.0297 - val_mae: 0.0670\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1748 - mse: 0.0203 - mae: 0.0576 - val_loss: 0.2017 - val_mse: 0.0269 - val_mae: 0.0696\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1696 - mse: 0.0175 - mae: 0.0512 - val_loss: 0.1770 - val_mse: 0.0216 - val_mae: 0.0542\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1663 - mse: 0.0164 - mae: 0.0477 - val_loss: 0.1654 - val_mse: 0.0162 - val_mae: 0.0432\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1617 - mse: 0.0155 - mae: 0.0456 - val_loss: 0.1840 - val_mse: 0.0228 - val_mae: 0.0661\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1553 - mse: 0.0140 - mae: 0.0414 - val_loss: 0.1784 - val_mse: 0.0205 - val_mae: 0.0483\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1523 - mse: 0.0126 - mae: 0.0375 - val_loss: 0.1776 - val_mse: 0.0210 - val_mae: 0.0508\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1590 - mse: 0.0143 - mae: 0.0419 - val_loss: 0.1805 - val_mse: 0.0207 - val_mae: 0.0528\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1557 - mse: 0.0137 - mae: 0.0402 - val_loss: 0.1758 - val_mse: 0.0207 - val_mae: 0.0454\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1521 - mse: 0.0128 - mae: 0.0379 - val_loss: 0.1625 - val_mse: 0.0157 - val_mae: 0.0396\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1499 - mse: 0.0118 - mae: 0.0354 - val_loss: 0.2060 - val_mse: 0.0309 - val_mae: 0.0790\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1578 - mse: 0.0137 - mae: 0.0405 - val_loss: 0.1736 - val_mse: 0.0203 - val_mae: 0.0508\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1578 - mse: 0.0138 - mae: 0.0405 - val_loss: 0.1586 - val_mse: 0.0150 - val_mae: 0.0439\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1475 - mse: 0.0115 - mae: 0.0347 - val_loss: 0.1403 - val_mse: 0.0106 - val_mae: 0.0314\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1515 - mse: 0.0120 - mae: 0.0358 - val_loss: 0.1571 - val_mse: 0.0142 - val_mae: 0.0454\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1565 - mse: 0.0136 - mae: 0.0392 - val_loss: 0.1750 - val_mse: 0.0191 - val_mae: 0.0511\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1576 - mse: 0.0138 - mae: 0.0404 - val_loss: 0.1721 - val_mse: 0.0179 - val_mae: 0.0520\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1481 - mse: 0.0118 - mae: 0.0348 - val_loss: 0.1687 - val_mse: 0.0183 - val_mae: 0.0460\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1491 - mse: 0.0115 - mae: 0.0342 - val_loss: 0.1782 - val_mse: 0.0198 - val_mae: 0.0605\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1542 - mse: 0.0126 - mae: 0.0368 - val_loss: 0.1575 - val_mse: 0.0136 - val_mae: 0.0365\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1544 - mse: 0.0132 - mae: 0.0383 - val_loss: 0.1560 - val_mse: 0.0152 - val_mae: 0.0417\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1467 - mse: 0.0113 - mae: 0.0335 - val_loss: 0.1763 - val_mse: 0.0194 - val_mae: 0.0457\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1497 - mse: 0.0113 - mae: 0.0339 - val_loss: 0.1689 - val_mse: 0.0179 - val_mae: 0.0477\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1554 - mse: 0.0128 - mae: 0.0372 - val_loss: 0.1453 - val_mse: 0.0123 - val_mae: 0.0366\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1538 - mse: 0.0129 - mae: 0.0372 - val_loss: 0.1612 - val_mse: 0.0169 - val_mae: 0.0409\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1440 - mse: 0.0105 - mae: 0.0314 - val_loss: 0.1670 - val_mse: 0.0180 - val_mae: 0.0418\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1474 - mse: 0.0111 - mae: 0.0325 - val_loss: 0.1617 - val_mse: 0.0153 - val_mae: 0.0366\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1495 - mse: 0.0116 - mae: 0.0338 - val_loss: 0.1601 - val_mse: 0.0155 - val_mae: 0.0452\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1559 - mse: 0.0132 - mae: 0.0385 - val_loss: 0.1591 - val_mse: 0.0138 - val_mae: 0.0425\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1464 - mse: 0.0110 - mae: 0.0327 - val_loss: 0.1568 - val_mse: 0.0155 - val_mae: 0.0397\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1462 - mse: 0.0108 - mae: 0.0317 - val_loss: 0.1639 - val_mse: 0.0143 - val_mae: 0.0405\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1549 - mse: 0.0130 - mae: 0.0372 - val_loss: 0.1702 - val_mse: 0.0175 - val_mae: 0.0375\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1505 - mse: 0.0118 - mae: 0.0345 - val_loss: 0.1579 - val_mse: 0.0163 - val_mae: 0.0395\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1459 - mse: 0.0107 - mae: 0.0317 - val_loss: 0.1587 - val_mse: 0.0155 - val_mae: 0.0439\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 25s 50ms/step - loss: 0.1480 - mse: 0.0108 - mae: 0.0320 - val_loss: 0.1668 - val_mse: 0.0162 - val_mae: 0.0469\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 25s 50ms/step - loss: 0.1511 - mse: 0.0119 - mae: 0.0343 - val_loss: 0.1582 - val_mse: 0.0130 - val_mae: 0.0422\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1515 - mse: 0.0122 - mae: 0.0352 - val_loss: 0.1643 - val_mse: 0.0160 - val_mae: 0.0403\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1442 - mse: 0.0105 - mae: 0.0314 - val_loss: 0.1689 - val_mse: 0.0185 - val_mae: 0.0426\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1467 - mse: 0.0107 - mae: 0.0315 - val_loss: 0.1672 - val_mse: 0.0178 - val_mae: 0.0405\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1533 - mse: 0.0122 - mae: 0.0353 - val_loss: 0.1595 - val_mse: 0.0136 - val_mae: 0.0384\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1513 - mse: 0.0122 - mae: 0.0351 - val_loss: 0.1576 - val_mse: 0.0146 - val_mae: 0.0369\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1433 - mse: 0.0102 - mae: 0.0305 - val_loss: 0.1522 - val_mse: 0.0130 - val_mae: 0.0360\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1484 - mse: 0.0111 - mae: 0.0327 - val_loss: 0.1669 - val_mse: 0.0173 - val_mae: 0.0437\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1519 - mse: 0.0119 - mae: 0.0345 - val_loss: 0.1641 - val_mse: 0.0173 - val_mae: 0.0427\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1519 - mse: 0.0121 - mae: 0.0353 - val_loss: 0.1579 - val_mse: 0.0154 - val_mae: 0.0385\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1399 - mse: 0.0096 - mae: 0.0286 - val_loss: 0.1783 - val_mse: 0.0196 - val_mae: 0.0440\n",
            "70/70 [==============================] - 5s 32ms/step - loss: 0.1571 - mse: 0.0139 - mae: 0.0335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVozVO6-vtO3"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msEYwMhNddcK"
      },
      "source": [
        "# 1024 / 512\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/deepf0/checkpoints', '20210502-204318_1024_512_100_Epochs', '87-0.16.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb4YnOFA_dqZ"
      },
      "source": [
        "# 512 / 256\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/deepf0/checkpoints', '20210503-142217_512_256_100_Epochs', '48-0.22.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM3NbC0mkbmg"
      },
      "source": [
        "# 256 / 128\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/deepf0/checkpoints', '20210503-193625_256_128_100_Epochs', '91-0.22.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmvJr2v9lCmz"
      },
      "source": [
        "from rt_pie.utils import converters\n",
        "def prediction():\n",
        "    predicted_c = []\n",
        "    true_c = []\n",
        "    inp_vector = []\n",
        "    predicted_vector = []\n",
        "    for inp, outp in dataset_test:\n",
        "        predicted = model.predict(inp)\n",
        "        predicted_vector.append(predicted)\n",
        "        inp_vector.append(outp) \n",
        "        true_cents = converters.convert_bin_to_local_average_cents(outp)\n",
        "        true_c.append(true_cents)\n",
        "        predicted_cents = converters.convert_bin_to_local_average_cents(np.squeeze(predicted))\n",
        "        predicted_c.append(predicted_cents)\n",
        "\n",
        "    predicted_vector = np.reshape(np.array(predicted_vector), ((len(predicted_vector) * len(predicted_vector[0]), 360)))\n",
        "    inp_vector = np.reshape(np.array(inp_vector), ((len(inp_vector) * len(inp_vector[0]), 360)))\n",
        "    \n",
        "    true_c = np.reshape(np.array(true_c), (1, (len(true_c)*len(true_c[0]))))\n",
        "    true_c = np.squeeze(true_c)\n",
        "    true_hz = converters.convert_cent_to_hz(true_c)\n",
        "    predicted_c = np.reshape(np.array(predicted_c), (1, (len(predicted_c)*len(predicted_c[0]))))\n",
        "    predicted_c = np.squeeze(predicted_c)\n",
        "    predicted_hz = converters.convert_cent_to_hz(predicted_c)\n",
        "    diff = true_hz - predicted_hz\n",
        "    return predicted_hz, true_hz, true_c, predicted_c, diff, inp_vector, predicted_vector"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ucPJnobUMw"
      },
      "source": [
        "from rt_pie.utils import converters\n",
        "def prediction():\n",
        "    predicted_c = []\n",
        "    true_c = []\n",
        "    inp_vector = []\n",
        "    predicted_vector = []\n",
        "    for inp, outp in dataset_test:\n",
        "        predicted = model.predict(inp)\n",
        "        predicted_vector.append(predicted)\n",
        "        inp_vector.append(outp) \n",
        "        true_cents = converters\n",
        "        true_c.append(true_cents)\n",
        "        predicted_cents = converters.convert_bin_to_local_average_cents(np.squeeze(predicted))\n",
        "        predicted_c.append(predicted_cents)\n",
        "\n",
        "    predicted_vector = np.reshape(np.array(predicted_vector), ((len(predicted_vector) * len(predicted_vector[0]), 360)))\n",
        "    inp_vector = np.reshape(np.array(inp_vector), ((len(inp_vector) * len(inp_vector[0]), 360)))\n",
        "    \n",
        "    true_c = np.reshape(np.array(true_c), (1, (len(true_c)*len(true_c[0]))))\n",
        "    true_c = np.squeeze(true_c)\n",
        "    true_hz = converters.convert_cent_to_hz(true_c)\n",
        "    predicted_c = np.reshape(np.array(predicted_c), (1, (len(predicted_c)*len(predicted_c[0]))))\n",
        "    predicted_c = np.squeeze(predicted_c)\n",
        "    predicted_hz = converters.convert_cent_to_hz(predicted_c)\n",
        "    diff = true_hz - predicted_hz\n",
        "    return predicted_hz, true_hz, true_c, predicted_c, diff, inp_vector, predicted_vector"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh3HIl3f7ONH"
      },
      "source": [
        "predicted_hz, true_hz, true_cent, predicted_cent, diff, inp_vector, predicted_vector = prediction()"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4LPGpFaYwvU"
      },
      "source": [
        "### Prediction Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUs_jXsA-8h5"
      },
      "source": [
        "## Hertz filter\n",
        "combined = zip(true_hz, predicted_hz)\n",
        "filtered = [x for x in list(combined) if x[0] > 60 and x[1] > 60 and x[1] < 400]\n",
        "filtered_unzipped = np.array(list(zip(*filtered)))\n",
        "diff_filtered = filtered_unzipped[0] - filtered_unzipped[1]\n",
        "\n",
        "## Cent filter\n",
        "combined_cent = zip(true_cent, predicted_cent)\n",
        "filtered_cent = [x for x in list(combined_cent) if x[0] > 3101.95500087 and x[1] > 3101.95500087]\n",
        "filtered_c_unzipped = np.array(list(zip(*filtered_cent)))\n",
        "diff_filtered_cent = filtered_c_unzipped[0] - filtered_c_unzipped[1]"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAMZz2UdkylA"
      },
      "source": [
        "## Hz Values with factor 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNSM6rADKWzQ"
      },
      "source": [
        "np.set_printoptions(threshold=360)\n",
        "counter = 0\n",
        "trues = np.array([])\n",
        "preds = np.array([])\n",
        "for i in range(len(diff)):\n",
        "    if diff[i] > -50 and diff[i] < 50  and true_hz[i] > 60:\n",
        "        plt.figure(i)\n",
        "        plt.plot(inp_vector[i], 'r')\n",
        "        plt.plot(predicted_vector[i], 'b')\n",
        "        plt.plot(np.argmax(inp_vector[i]),np.max(inp_vector[i]),'x')\n",
        "        plt.plot(np.argmax(predicted_vector[i]),np.max(predicted_vector[i]),'x')\n",
        "        plt.text(np.argmax(inp_vector[i])+10,np.max(inp_vector[i]),f'max={np.max(inp_vector[i]):.1f} @ bin {np.argmax(inp_vector[i])}')\n",
        "        plt.text(np.argmax(predicted_vector[i])+10,np.max(predicted_vector[i]),f'max={np.max(predicted_vector[i]):.1f} @ bin {np.argmax(predicted_vector[i])}')\n",
        "        plt.show()\n",
        "\n",
        "        \n",
        "        print('True Hz: ', true_hz[i], 'Predicted Hz: ',predicted_hz[i])\n",
        "        #trues = np.append(trues, filtered_unzipped[0][i])\n",
        "        #preds = np.append(preds, filtered_unzipped[1][i])\n",
        "        # counter += 1\n",
        "        # if counter == 60:\n",
        "        #     break   \n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRJb_B_ryvm5",
        "outputId": "08b9c6da-043a-47e4-8d8a-5ee05f369f17"
      },
      "source": [
        "divided = np.divide(preds, trues)\n",
        "np.mean(divided)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.621543653541332"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-AXsfqli1Nl"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr6y9h0_cCRJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "outputId": "de5a5bec-3953-4e14-89a9-42e71beb55ec"
      },
      "source": [
        "from rt_pie.utils import metrics\n",
        "hz_metrics = metrics.get_hz_metrics(filtered_unzipped[0], filtered_unzipped[1], print_output=True, rpa_relative_tolerance=0.05)\n",
        "rpa_cent = metrics.raw_pitch_accuracy_cent(filtered_c_unzipped[0], filtered_c_unzipped[1])\n",
        "print(rpa_cent)\n",
        "hist = histogram(diff_filtered)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min abs err [Hz] _______ 0.0\n",
            "Max abs err [Hz] ____ 177.74\n",
            "Mean err [Hz] ________ -1.87\n",
            "Median [Hz] __________ -0.01\n",
            "MAE [Hz] ______________ 5.82\n",
            "StdDev [Hz] __________ 14.12\n",
            "5% quant err [Hz] ___ -11.55\n",
            "95% quant err [Hz] ____ 8.68\n",
            "RPA [Hz] _____________ 86.27\n",
            "66.24434083384013\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEKCAYAAADTgGjXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1f3/8dcHBBGlglQxCdZQpaxiSCLiRqkLUARc22q14kZ4tGK19aug1gJu1RZbRftVoaWAdat7QL6K+JPaWhEJBFcQUJBNVFRUEKr4+f0xN+MQJpM7YSaz5P18PPLIzLnnnvlMtk/uOeeeY+6OiIhIQzTLdAAiIpK7lERERKTBlERERKTBlERERKTBlERERKTBlERERKTB0pZEzGyKmb1vZq/FlO1jZs+Y2bLgc7ug3MxsopktN7NXzKw05pzhQf1lZjY8przMzF4NzploZpau9yIiIvGl80pkKjCoVtkY4Fl37ww8GzwH+CHQOfioAO6ESNIBxgKHA32AsTWJJ6gzIua82q8lIiJplrYk4u7PAx/VKj4JmBY8ngacHFM+3SPmAW3NrAAYCDzj7h+5+8fAM8Cg4Ni33H2eR+6WnB7TloiINJLdGvn1Orj7+uDxe0CH4HERsDqm3pqgLFH5mjjlcZlZBZErHPbcc8+yrl277sJbkKZg+fLlABx88MEJ61VVVUUfl5WV1VsvUR2RbFVVVfWhu+8b71hjJ5Eod3cza5Q1V9x9EjAJoLy83BcsWNAYLytNQOxQXKKfq5p6+tmTXGRmq+o61tizszYEXVEEn98PytcCB8TU6xiUJSrvGKdcREQaUWMnkUqgZobVcOCJmPJzgllafYFNQbfX08AAM2sXDKgPAJ4Ojn1qZn2DWVnnxLQlIiKNJG3dWWZ2P9Af+LaZrSEyy+om4B9mdgGwCvhxUH0WMBhYDmwBzgNw94/M7Drg5aDete5eM1j/CyIzwPYA/i/4EEmJmu4nrXItkpg1tV8SjYlIGGGTSOyYSKK6Sko7+/LLL1mzZg1bt27NdCgSaNWqFR07dqRFixY7lJtZlbuXxzsnYwPrItks2T/29dVX8tjZmjVraNOmDcXFxehe4cxzdzZu3MiaNWvo1KlT6PO07ImIZMTWrVtp3769EkiWMDPat2+f9JWhkoiIZIwSSHZpyPdDSUQkjqFDhzJ06NDQ9eu7ibCsrEw3GkpeUhIRiWPmzJnMnDkzdP2FCxfWe7y+OpLb+vfvH72ZdPDgwXzyyScZjqhxaGBdJI7KysqUtqcZgU3LrFmzMh1Co9GViEgcyXZn1UfdWdlp5cqVdO3alXPPPZfvfe97nHXWWcyZM4ejjjqKzp07M3/+fDZv3sz5559Pnz596N27N088Ebmv+YsvvuCMM86gW7dunHLKKXzxxRfRdouLi/nwww8BOPnkkykrK6NHjx5MmjQpWmevvfbi6quv5tBDD6Vv375s2LChcd98iiiJiEhWMLM6P2L/+E6aNClh3WQtX76cyy67jCVLlrBkyRLuu+8+/v3vfzNhwgRuvPFGbrjhBo499ljmz5/Pc889x+WXX87mzZu58847ad26NW+++Sbjx4/fYTHOWFOmTKGqqooFCxYwceJENm7cCMDmzZvp27cvixcvpl+/fkyePLlhX7gMU3eWSBw1f7QqKipS0l5NO7F/DCU7dOrUiUMOOQSAHj16cNxxx2FmHHLIIaxcuZI1a9ZQWVnJhAkTgMjU5HfffZfnn3+eX/7ylwD06tWLXr16xW1/4sSJPPbYYwCsXr2aZcuW0b59e1q2bMmQIUOAyJXqM888k+63mhZKIiJxjBw5EkhdEqn5L1NJpG5hb8isqKhI2fcFYPfdd48+btasWfR5s2bN+Oqrr2jevDmPPPIIXbp0SbrtuXPnMmfOHF588UVat25N//79o/dhtGjRInrl1Lx5c7766qsUvJvGp+4skThGjBjBiBEjQtff69CBaYxGMmngwIHcfvvt0SS3aNEiAPr168d9990HwGuvvcYrr7yy07mbNm2iXbt2tG7dmiVLljBv3rzGC7yR6EpEJI5krxjaD7o4TZFIpl1zzTVceuml9OrVi6+//ppOnToxc+ZMfv7zn3PeeefRrVs3unXrFnfixKBBg7jrrrvo1q0bXbp0oW/fvhl4B+mlBRhFdkFNd8SBo2ey8qYT663X1H7fEnnzzTfp1q1bpsOQWuJ9XxItwKjuLJE41q1bx7p160LX3/be8jRGI5K9lERE4igqKqKoqCh0/femXZrGaESyl8ZEROIoKCjIdAgiOUFJRCSOZLqyRJoydWeJiEiDKYmIiEiDKYmIxKEFE0XC0ZiISBza+0MkHF2JiMSxYMGCpPYA2X/4rSltTxrHriwFv3LlSo455hhKS0spLS3lP//5DxBZL6t///6cfvrpdO3albPOOiuvbzLVlYhIHMl2Ze2+/8Epba+pSdde62H+eC9fvpyHHnqIKVOmcNhhh0WXgq+srOTGG2+ke/fuHHvssUyZMoVPPvmEPn36cPzxx7PffvvxzDPP0KpVK5YtW8aZZ54Z/Udh0aJFvP766xQWFnLUUUfxwgsvcPTRR6flPWaakoiINGkNXQq+sLCQUaNGUV1dTfPmzXnrrbeibfbp04eOHTsCUFJSwsqVK5VERJqScePG7fC5Phufuh0SrJ2l/UQSy2R3T0OXgh83bhwdOnRg8eLFfP3117Rq1Spum7m8zHsYGhMRiWP8+PGMHz8+dP3PFz+d8PjkyZNzdue6pq6upeA3bdpEQUEBzZo145577mH79u2ZDDNjdCUiEsfYsWNT2t7dd9+d0vak8dS1FPwvfvELTjvtNKZPn86gQYPYc889Mx1qRmgpeJFdEDsg3NR+l3aVloLPTloKXkREGo2SiEgcVVVVVFVVpay9SZMmaVBd8pLGRETiKC+PXLmnqotq5MiRwDeztETyhZKISBylpaVJ1W/Z4aA0RSKS3ZREROJItiur4Nzb0hSJSHbTmIiIiDSYkoiINFnFxcUccsghlJSURMfBAEaPHk2vXr0455xzomV///vfufXWxAttptuNN964w/MjjzwSiCwG2bNnz0yElJkkYma/MrPXzew1M7vfzFqZWScze8nMlpvZg2bWMqi7e/B8eXC8OKadK4PypWY2MBPvRfJTYWEhhYWFoeuvunlIGqORdHruueeorq6OLp64adMmFi5cyCuvvELLli159dVX+eKLL/jb3/7GRRddlNFYayeRmpWDM6nRk4iZFQG/BMrdvSfQHDgDuBn4k7sfDHwMXBCccgHwcVD+p6AeZtY9OK8HMAj4XzNr3pjvRfLX+vXrWb9+fabDkAxo1qwZX375Je7Oli1baNGiBRMmTODiiy+mRYsWcc9xd0aNGkWXLl04/vjjGTx4MA8//DAQudr58MMPgciWAP379wdg/vz5HHHEEfTu3ZsjjzySpUuXAjB16lROPfVUBg0aROfOnbniiisAGDNmDF988QUlJSWcddZZAOy11147xbJ9+3Yuv/xyDjvsMHr16pX21RIy1Z21G7CHme0GtAbWA8cCDwfHpwEnB49PCp4THD/OIrcJnwQ84O7b3P0dYDnQp5Hilzy3du1a1q5dm+kwmhQz22lJ+KFDh2JmzJgxI1o2adIkzGyH6dLr1q3DzJK6eqx5zQEDBlBWVha9j6dNmzYMHjyY3r17U1BQwN57781LL73EySefXGc7jz32GEuXLuWNN95g+vTpoa4Qunbtyr/+9S8WLVrEtddey1VXXRU9Vl1dzYMPPsirr77Kgw8+yOrVq7npppvYY489qK6u5t57762z3b/+9a/svffevPzyy7z88stMnjyZd955J4mvSnIafXaWu681swnAu8AXwGygCvjE3WuWulwDFAWPi4DVwblfmdkmoH1QPi+m6dhzdmBmFUAFwHe+852Uvh/JT8n+MZLc9O9//5uioiLef/99TjjhBLp27Uq/fv244oorolcAF154Iddeey1/+ctfmD17Nr169eI3v/nNDu08//zznHnmmTRv3pzCwkKOPfbYel9706ZNDB8+nGXLlmFmfPnll9Fjxx13HHvvvTcA3bt3Z9WqVRxwwAGh3tPs2bN55ZVXoldCmzZtYtmyZXTq1CnU+cnKRHdWOyJXEZ2AQmBPIt1RaePuk9y93N3L991333S+lIg0kLvvdHPnjBkzcHeGDh0aLauoqMDdd1gBoLCwEHdn3bp1Sb1mUVHk/8799tuPU045hfnz5+9wfNGiRbg7Xbp04aGHHuIf//gHK1asYNmyZaFfY7fdduPrr78GInuR1Ljmmmv4wQ9+wGuvvcaMGTN2OLYrS8m7O7fffjvV1dVUV1fzzjvvMGDAgNDnJysT3VnHA++4+wfu/iXwKHAU0Dbo3gLoCNT0JawFDgAIju8NbIwtj3OOyC6pqKjQ3eV5bvPmzXz22WfRx7Nnz95phtM111zDddddx5dffhld6r1Zs2Zs2bJlh3r9+vXjwQcfZPv27axfv57nnnsueqy4uDh639EjjzwSLd+0aVM0iU2dOjVUzC1atNjhiiWegQMHcuedd0brvfXWW2zevDlU+w2RiSTyLtDXzFoHYxvHAW8AzwGnB3WGA08EjyuD5wTH/59H/l2pBM4IZm91AjoDO/4bIdJA2v8j/23YsIGjjz6aQw89lD59+nDiiScyaNA3nSKPP/445eXlFBYW0rZtW0pKSjjkkEPYunUrhx566A5tnXLKKXTu3Jnu3btzzjnncMQRR0SPjR07lksuuYTy8nKaN/9m7s8VV1zBlVdeSe/evUNfaVRUVNCrV6/owHo8F154Id27d6e0tJSePXsycuTItG6KlZGl4M1sPPAT4CtgEXAhkfGMB4B9grKz3X2bmbUC7gF6Ax8BZ7j720E7VwPnB+1c6u7/V99rayl4CaOmq6S+q5GageB9Bo6K7G64i+01Jfm8FPy5557LkCFDOP300+uvnGWSXQo+I8ueuPtYoPauP28TZ3aVu28FflRHOzcAN6Q8QGnykv1j36Yk8bCekofkK62dJSKSYmHHOPKBlj0RiWPGjBk73JtQn8+qn0p4XPuJSL7S9rgicdSMddT3+xF2e9yw7TUl+TwmkstyYkxEJNsNGZLatbBGjBiR0vZEsoWSiEgcyXRlhaGuLMlXGhMRkSbrtttuo2fPnvTo0WOHZd7HjRtHUVERJSUllJSUMGvWLABeeOEFevXqRXl5efSu9U8++YQBAwZE70rPhMcff5w33ngj+vy3v/0tc+bMAaB///6kswtfSUSkEVRVVSW9W6Kk12uvvcbkyZOZP38+ixcvZubMmSxfvjx6/Fe/+lV06ZDBgwcDcMsttzBr1ixuvfVW7rrrLgCuv/56rrrqKpo1y9yf09pJ5Nprr+X4449vlNdWEhGJI96KsruivLx8h02PJPPefPNNDj/8cFq3bs1uu+3G97//fR599NGE57Ro0YItW7ZEl4hfsWIFq1evji7vHs9TTz1F165dKS0t5Ze//GV0vG3cuHFMmDAhWq9nz56sXLkSgJNPPpmysjJ69OixQ1foXnvtxdVXX82hhx5K37592bBhA//5z3+orKzk8ssvp6SkhBUrVnDuuedGF2CMNXv2bI444ghKS0v50Y9+xOeff57EVyw+JRGRBioe82SmQ8grNYk77EdZWVnc88Pq2bMn//rXv9i4cSNbtmxh1qxZrF69Onr8jjvuoFevXpx//vl8/PHHAFx55ZWcc845/O53v2PUqFFcffXVXH/99XW+xtatWxkxYgQzZsygqqqK9957L1RsU6ZMoaqqigULFjBx4kQ2btwIRNb46tu3L4sXL6Zfv35MnjyZI488kmHDhvGHP/yB6upqDjrooLhtfvjhh1x//fXMmTOHhQsXUl5ezh//+MewX646KYmIxBFvRdlEDhw9M43RSDp069aN0aNHM2DAAAYNGkRJSUl0bauf//znrFixgurqagoKCrjssssAKCkpYd68eTz33HO8/fbbFBQU4O785Cc/4eyzz2bDhg07vMaSJUvo1KkTnTt3xsw4++yzQ8U2ceLE6NXG6tWro+MvLVu2jF7JlJWVRa9cwpg3bx5vvPEGRx11FCUlJUybNo1Vq1aFPr8ump0lIllhV++hacj5F1xwARdcENlE9aqrrqJjx44AdOjQIVpnxIgRO035dneuv/56HnjgAS6++GJ+//vfs3LlSiZOnMgNN4RbiSl2iXj4Zpn4uXPnMmfOHF588UVat25N//79o8datGgRvdpqyBLxJ5xwAvfff3/oc8LQlYiINFnvv/8+AO+++y6PPvooP/3pTwF22Br5scce22mJ+OnTpzN48GD22WcftmzZQrNmzeIuEd+1a1dWrlzJihUrAHb4A15cXMzChQsBWLhwYXT3wU2bNtGuXTtat27NkiVLmDdvHvVp06ZNdFn7uvTt25cXXnghOnlg8+bNvPXWW/W2XR9diYjEUbMJUtj7RdZPvQRuOjGdIUkanHbaaWzcuJEWLVrw5z//mbZt2wKRZdqrq6sxM4qLi3fYp3zLli1MnTqV2bNnA/DrX/+awYMH07JlS+67774d2m/VqhWTJk3ixBNPpHXr1hxzzDHRP/annXYa06dPp0ePHhx++OF873vfA2DQoEHcdddddOvWjS5dutC3b99638cZZ5zBiBEjmDhxYtwBdYB9992XqVOncuaZZ7Jt2zYgMrOs5nUbSsueiMQRZpmS4jFPsurmb7o5tOxJcprisidz585lwoQJzJyZvWNoWvZEJAUqKyszHYJITlASEYkjdk9vkVTp379/wntKcpEG1kUkY9S9l10a8v1QEhGJQ/t/pF+rVq3YuHGjEkmWcHc2btxIq1atkjpP3VkicYwcORLQtrbp1LFjR9asWcMHH3yQ6VAk0KpVq+i9MmHVm0TM7BLgb8BnwF+A3sAYd5/dkCBFckGy+3/sdejAlLbXFLRo0YJOnTplOgzZRWGuRM5399vMbCDQDvgZcA+gJCJ5K9murPaDLk5peyK5IsyYSM2KZoOBe9z99ZgyERFpwsIkkSozm00kiTxtZm2AzO2+ItII1q1bx7p160LX3/be8oTHtZ+I5KuE3VkWuc32t8C+wNvuvsXM2gPnNUZwIplSVFQEhJ/y+N60S2HqJXUer9lLRDORJN8kTCLu7mY2y90PiSnbCGxMe2QiGVRQUJDS9kpLS1Panki2CDOwvtDMDnP3l9MejUiWSKYrKwx1ZUm+CpNEDgfOMrNVwGYig+ru7r3SGpmIiGS9MEkk8QR4ERFpsuqdneXuq4C2wNDgo21QJpK3ysrKdtrDe1cku/+3SK6oN4kEd6zfC+wXfPzdzBLfWSWS4xYuXBjddU5E6hamO+sC4HB33wxgZjcDLwK3pzMwkUxKduOy/YffmqZIRLJbmCRiwPaY59vRHeuS55Ltytp9/4PTFIlIdguTRP4GvGRmjwXPTwb+mr6QREQkVyQcEzGzZsA8IneofxR8nOfuunaXvDZu3DjGjRsXuv7Gp9S7K02T1bcMg5ktcvfeKX1Rs7ZElpXvCThwPrAUeBAoBlYCP3b3j4OlV24jsnbXFuBcd18YtDMc+E3Q7PXuPq2+1y4vL/dk+7ul6amZSZXo96N4zJOsunlI9HmiumHaE8lWZlbl7uXxjoXpznrWzE4DHvXU/QbcBjzl7qebWUugNXAV8Ky732RmY4AxwGjgh0Dn4ONw4E7gcDPbBxgLlBNJRFVmVunuH6coRmnCxo4dm+kQRHJCmCQyEvg18JWZbeWbO9a/1ZAXNLO9gX7AuUQa+i/wXzM7CegfVJsGzCWSRE4CpgcJbJ6ZtTWzgqDuM+7+UdDuM8Ag4P6GxCUSK5muLJGmLMyYyCB3b+buLd39W+7epqEJJNAJ+AD4m5ktMrO/mNmeQAd3Xx/UeQ/oEDwuAlbHnL8mKKurPN77qDCzBWa2QFtxioikTsIk4u5fA3ek+DV3A0qBO4Oxls1Euq5iX9eJdFGlhLtPcvdydy/fd999U9Ws5DHt/yESTphNqZ41s9MsdWs2rAHWuPtLwfOHiSSVDUE3FcHn94Pja4EDYs7vGJTVVS6yy8rLy6N7gCSjeMyTFI95Mg0RiWSnMElkJPAQsM3MPjWzz8zs04a+oLu/B6w2sy5B0XHAG0AlMDwoGw48ETyuBM6xiL7ApqDb62lggJm1M7N2wICgTGSXlZaWJrUHSMsOB6W0PZFcUe/Auru3ScPrXgzcG8zMepvIfSjNgH+Y2QXAKuDHQd1ZRKb3Licyxfe8IK6PzOw6oGafk2trBtlFdlWyXVkF596W0vZEckWdScTMznb3vwePj3L3F2KOjXL3Bo+VuHs1kam5tR0Xp64DF9XRzhRgSkPjEBGRXZOoO+vXMY9r3457fhpiERGRHJMoiVgdj+M9F8krhYWFFBYWhq4fe+d6PNpPRPJVojERr+NxvOcieWX9+vX1VxKRhEmkq5m9QuSq46DgMcHz76Y9MpEMWrs2tbPFtWaW5KtESaRbo0UhkmWS6coSacrqTCLaR11EROoT5mZDkSanoqKCioqKlLVXVlaW9G6JIrkgzCq+Ik3O5MmTAZg0aVJK2lu4cGFK2hHJNoluNnzW3Y8zs5vdfXRjBiWSaXfffXdS9fcZOCpNkYhkt0RXIgVmdiQwzMweoNa9ITW7C4rko2S7stqUDEpTJCLZLVES+S1wDZHVcf9Y65gDx6YrKBERyQ2JZmc9DDxsZte4+3WNGJNIxs2YMQOAoUOHhqr/WfVTwIlpjEgkO4VZxfc6MxtGZEtbgLnuPjO9YYlk1rBhw4DwNwl+9PQdFI9Rl5Y0PfUmETP7HdAHuDcousTMjnT3q9IamUgGDRmSeC0sEYkIM8X3RKAk2CoXM5sGLAKURCRv1XRniUhiYW82bBvzeO90BCIiIrknzJXI74BFZvYckWm+/YAxaY1KRERyQpiB9fvNbC5wWFA0OtgnXSRv1ez9odV3RRILteyJu68HKtMci4iI5BitnSUSR7JXIAeOTjzrXVc0kq+0iq+IiDRYwiRiZs3NbEljBSMiIrklYRJx9+3AUjP7TiPFI5IVhg4dGnrJE4D1Uy9JeFz7iUi+CjMm0g543czmA5trCt19WNqiEsmwmTOTW9nnvxtWJDyu/UQkX4VJItekPQqRLFNZmdrJiAsWLEhpeyLZIsx9Iv80swOBzu4+x8xaA83TH5pI5iTTlRWGurIkX9U7O8vMRgAPAzVbvRUBj6czKJFsVzzmyUyHIJIVwkzxvQg4CvgUwN2XAfulMyiRTJs0aVLK9leHyE6Jye6WKJILwiSRbe7+35onZrYbkZ0NRfLWyJEjGTlyZMramzx5MpMnT05ZeyLZIszA+j/N7CpgDzM7AfgFoHWyJa+NGDEiqfp7HTowTZGIZLcwSWQMcAHwKjASmAX8JZ1BiWRasl1Z7QddnKZIRLJbmNlZXwcbUb1EpBtrqWshIBERIdzsrBOBFcBE4A5guZn9MN2BiWTSunXrWLduXej6295bnsZoRLJXmIH1W4AfuHt/d/8+8APgT+kNSySzioqKKCoqCl3/vWmXpjEakewVZkzkM3eP/TfrbeCzNMUjkhUKCgoyHYJITqjzSsTMTjWzU4EFZjbLzM41s+FEZma9vKsvHKwQvMjMZgbPO5nZS2a23MweNLOWQfnuwfPlwfHimDauDMqXmpmmx0jKJNudJdJUJerOGhp8tAI2AN8H+gMfAHuk4LUvAd6MeX4z8Cd3Pxj4mMiMMILPHwflfwrqYWbdgTOAHsAg4H/NTMuxiIg0ojq7s9z9vHS9qJl1BE4EbgB+bZENrY8FfhpUmQaMA+4ETgoeQ2T5lTuC+icBD7j7NuAdM1sO9AFeTFfcIiKyo3rHRMysE3AxUBxbfxeXgr8VuAJoEzxvD3zi7l8Fz9cQWaOL4PPq4DW/MrNNQf0iYF5Mm7Hn1H4PFUAFwHe+o61RpH41CyZWVVVlOBKR7BZmYP1x4K9ExkK+3tUXNLMhwPvuXmVm/Xe1vTDcfRIwCaC8vFz3uEi9tP+HSDhhkshWd5+Ywtc8ChhmZoOJjLd8C7gNaGtmuwVXIx2BtUH9tcABwJpg3a69gY0x5TVizxHZJcnu/7H/8FtT2p5IrgiTRG4zs7HAbGBbTaG7N+hfNXe/ErgSILgS+R93P8vMHgJOBx4AhgNPBKdUBs9fDI7/P3d3M6sE7jOzPwKFQGdgfkNiEqkt2f0/dt//4JS2J5IrwiSRQ4CfERn4runO8uB5Ko0GHjCz64FFRLrQCD7fEwycf0RkRhbu/rqZ/QN4A/gKuCjYE15ERBpJmCTyI+C7scvBp4q7zwXmBo/fJjK7qnadrUEM8c6/gcgML5GUGjdu3A6f67PxqdsTLsJYs5dIKvcoEckGVt9aimb2OFDh7u83TkjpVV5e7uqflvpEZpFDXb8fNTsbrrp5SLTswNEzo49X3nRiUu2JZDMzq3L38njHwlyJtAWWmNnL7DgmsitTfEWy2tixY1Pa3t13311/JZEcFCaJpPa3SSQHhO3GCktb40q+CrOfyD8bIxAREck9Ye5Y/4xv9lRvCbQANrv7t9IZmEgm1dypnqqpuTUD6roikXwT5kqkZmkSYtas6pvOoEQyrbw8MoaYqoHwkSNHAkoikn/CbEoV5RGPA1p2XfJaaWkppaWloeu37HBQGqMRyV5hurNOjXnaDCgHtqYtIpEskOzCiwXn3pamSESyW5jZWUNjHn8FrCTSpSUiIk1cmDGRtO0rIiIiua3OJGJmv01wnrv7dWmIRyQrFBYWAoTeInfVzUN2uGNdpKlIdCWyOU7ZnkS2q20PKIlI3lq/fn2mQxDJCYm2x72l5rGZtSGyJ/p5RJZqv6Wu80Tywdq12ppGJIyEYyJmtg/wa+AsIvuel7r7x40RmEgm1XRniUhiicZE/gCcSmRb2UPc/fNGi0pERHJCopsNLyOyY+BvgHVm9mnw8ZmZfdo44YlkRkVFhe4uFwkh0ZhIUnezi+STyZMnA9pESqQ+YW42FGlykt3/Y5+Bo1LankiuUBIRiSPZrqw2JYNS2p5IrlCXlYiINJiSiEgcM2bMYMaMGaHrfxWX7MYAAAwySURBVFb91E5lNfuwQ2RsReMrko/UnSUSx7Bhw4Dw+4l89PQdCbu0tJ+I5CslEZE4hgwZktL2RowYkdL2RLKFkohIHMl0ZcUT25UFmios+UtjIiJJqJ0cRJo6JRGRRlBVVZX0bokiuUDdWSJxmBkQf2C9IVcj5eXldbYnkst0JSIiIg2mKxGROJK9YtCuhtJU6UpEREQaTElEREQaTElEJI6hQ4cydOjQ0PXXT70kjdGIZC+NiYjEMXNmcmMc/92wIk2RiGQ3JRGROCorKzMdgkhOaPTuLDM7wMyeM7M3zOx1M7skKN/HzJ4xs2XB53ZBuZnZRDNbbmavmFlpTFvDg/rLzGx4Y78XyV/JdmeJNFWZGBP5CrjM3bsDfYGLzKw7MAZ41t07A88GzwF+CHQOPiqAOyGSdICxwOFAH2BsTeIREZHG0ehJxN3Xu/vC4PFnwJtAEXASMC2oNg04OXh8EjDdI+YBbc2sABgIPOPuH7n7x8AzQOLt5URC0v4fIuFkdHaWmRUDvYGXgA7uvj449B7QIXhcBKyOOW1NUFZXebzXqTCzBWa24IMPPkhZ/JK/Ro4cGd0DRETqlrGBdTPbC3gEuNTdP61ZqwjA3d3MUrbIkLtPAiYBlJeXa/EiqVey+3/sdejAlLYnkisykkTMrAWRBHKvuz8aFG8wswJ3Xx90V70flK8FDog5vWNQthboX6t8bjrjlqYj2a6s9oMuTml7IrkiE7OzDPgr8Ka7/zHmUCVQM8NqOPBETPk5wSytvsCmoNvraWCAmbULBtQHBGUiItJIMnElchTwM+BVM6sOyq4CbgL+YWYXAKuAHwfHZgGDgeXAFuA8AHf/yMyuA14O6l3r7h81zluQfLdu3ToACgsLQ9Xf9t5ydt//4DqP1+wlUlZWtuvBiWSRRk8i7v5vwOo4fFyc+g5cVEdbU4ApqYtOJKKoKDJHI+xqvu9NuzThSr7aT0Tyle5YF4mjoKAgpe2VlpbWX0kkBymJiMRR052VKtoaV/KVVvEVEZEGUxIREZEGUxIRiaOsrCylM6nMjNgbakXyhcZEROJYuHDhTmXFY57MQCQi2U1JRCSOBQsWJFV//+G3pikSkeymJCISR7JdWYluNBTJZxoTERGRBlMSEYlj3LhxjBs3LnT9jU/dnr5gRLKYkohIHOPHj2f8+PGh63++WGt/StOkMRGROMaOHZuytjSrS/KZkohIHMl0ZYk0ZerOEhGRBlMSEYmjqqoqJYsmqitL8p26s0Ti0P4fIuEoiYjEkez+Hy07HJTS9kRyhZKISBzJdmUVnHtbStsTyRVKIiL10LiGSN00sC4iIg2mJCISR2FhIYWFhaHrr7p5SMLj2k9E8pW6s0TiWL9+faZDEMkJSiIicaxduzal7WmqsOQrJRGROJLpyhJpyjQmIpJAqmZmFY95UrO8JC/pSkQkjoqKisiDfU5KSXvrp14CQDGw8qYTU9KmSDZQEhGJY/LkyQAcODo1SeS/G1akpB2RbKPuLJE47r77bvYZOCp0/WTqiuQTJRGROCoqKmhTMih0/WTqiuQTJREREWkwJRGROGbMmMGW5S+Frv9Z9VOh62qWluQTJRGRWorHPMmwYcP44JHrQp/z0dN3JP0aIvlAs7NE4tjjoMMyHYJITlASEQnEXh3sd/rYRn1d3TsiuUpJRITMdC+pS0vyQc6PiZjZIDNbambLzWxMpuOR3JMtf8yzJQ6RZOT0lYiZNQf+DJwArAFeNrNKd38js5Fln9g/UDVdJ7HdKDXHm0K3Spg/1jX7gxw4ema6wwG+ian296QpfD8kt+V0EgH6AMvd/W0AM3sAOAnImySS6A9JXYkhtizeH8zYstrHaz+vaSMb/5jVjitf/pNP9P2pSzZ+f6RpsFze58DMTgcGufuFwfOfAYe7+6ha9SqAYEU9ugBLEzT7beDDNITbGHI5dsjt+HM5dsjt+HM5dsiN+A90933jHcj1K5FQ3H0SMClMXTNb4O7laQ4pLXI5dsjt+HM5dsjt+HM5dsj9+HN9YH0tcEDM845BmYiINIJcTyIvA53NrJOZtQTOACozHJOISJOR091Z7v6VmY0CngaaA1Pc/fVdbDZUt1eWyuXYIbfjz+XYIbfjz+XYIcfjz+mBdRERyaxc784SEZEMUhIREZEGa7JJxMx+ZGavm9nXZlYeU15sZl+YWXXwcVfMsTIzezVYYmWimVlmoq87/uDYlUGMS81sYEx5Vi4RY2bjzGxtzNd8cMyxuO8lm2Tr17UuZrYy+DmuNrMFQdk+ZvaMmS0LPrfLdJw1zGyKmb1vZq/FlMWN1yImBt+LV8ysNHOR1xl7Tv+878Tdm+QH0I3IjYdzgfKY8mLgtTrOmQ/0BQz4P+CHWRh/d2AxsDvQCVhBZNJB8+Dxd4GWQZ3umf4+BDGPA/4nTnnc95LpeGvFmLVf1wQxrwS+Xavs98CY4PEY4OZMxxkTWz+gNPb3sq54gcHB76YFv6svZWHsOfvzHu+jyV6JuPub7p7ozvUdmFkB8C13n+eR7/h04OS0BViPBPGfBDzg7tvc/R1gOZHlYaJLxLj7f4GaJWKyWV3vJZvk4tc1npOAacHjaWTwZ7s2d38e+KhWcV3xngRM94h5QNvgdzcj6oi9Lrnw876TJptE6tHJzBaZ2T/N7JigrIjIIo811gRl2aYIWB3zvCbOusqzxaig+2FKTFdKtscMuRFjbQ7MNrOqYEkggA7uvj54/B7QITOhhVZXvLny/cjVn/ed5PR9IvUxsznA/nEOXe3uT9Rx2nrgO+6+0czKgMfNrEfagkyggfFnpUTvBbgTuI7IH7frgFuA8xsvuibnaHdfa2b7Ac+Y2ZLYg+7uZpYzc/9zLV7y7Oc9r5OIux/fgHO2AduCx1VmtgL4HpHlVDrGVE37EisNiZ/ES8FkbImYsO/FzCYDNeuv58KyNrkQ4w7cfW3w+X0ze4xIl8kGMytw9/VB98/7GQ2yfnXFm/XfD3ffUPM4B3/ed6LurFrMbN9gnxLM7LtAZ+Dt4NL5UzPrG8zKOgfIxquBSuAMM9vdzDoRiX8+WbxETK0+61OAmpksdb2XbJK1X9d4zGxPM2tT8xgYQOTrXQkMD6oNJzt/tmPVFW8lcE4wS6svsCmm2ysr5PjP+84yPbKfqQ8i37w1RK46NgBPB+WnAa8D1cBCYGjMOeVEvuErgDsI7vjPpviDY1cHMS4lZgYZkZkrbwXHrs709yAmrnuAV4FXiPwiFdT3XrLpI1u/rnXE+l0iM4AWBz/nVwfl7YFngWXAHGCfTMcaE/P9RLqZvwx+5i+oK14is7L+HHwvXiVm5mIWxZ7TP++1P7TsiYiINJi6s0REpMGUREREpMGUREREpMGUREREpMGUREREpMGUREQCZrY9ZmXV6nSuyGtm15pZ6JtJzay/mc2sVTbVzE5P8nVPNrPuyZwjkkhe37EukqQv3L0kUQUza+7u2+t6HvY8d//troWaPDPbjchChTOBNxr79SU/6UpEpB7B/hs3m9lC4Edxnp8Z7M/xmpndHHPe52Z2i5ktBo6o1Wb0KiJob7yZLQza6dqAGMuCBUOrzOzpmruizWyumd1qkX1DRgPDgD8EV1pH1bry2m5mBzb8KyVNka5ERL6xh5lVxzz/nbs/GDze6O6lAGZ2U81zMysE5gFlwMdEVsc92d0fB/Yksp/FZSFe+8OgvV8A/wNcGKfOMbXi+w4w08xaALcDJ7n7B2b2E+AGvlnUr6W7lwexdwZmuvvDwbGSoPwi4PvuvipErCJRSiIi30jUnfVgHc8PA+a6+wcAZnYvkY2IHge2A4+EfO1Hg89VwKl11PmXuw+peWJmU4OHXYCeRFbkhchGWbHrRdWOfQdmdhQwAjg6ZKwiUUoiIuFsrud5PFvDjJcEtgWft5P876UBr7v7EXUcrzPWoNvrr8Awd/88ydcV0ZiIyC6aD3zfzL4drP58JvDPRo5hKbCvmR0BYGYtEuyB8xlQs4pvC+AhYLS7v9UokUreURIR+cYetQaab6rvBI8sMz4GeI7IyrhV3sgbhnlkW97TgZuDQfxq4Mg6qj8AXG5mi4I65cD4mPdc2ChBS97QKr4iItJguhIREZEGUxIREZEGUxIREZEGUxIREZEGUxIREZEGUxIREZEGUxIREZEG+/+zwcl8dyxh8AAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y3oZ8LQKZV9"
      },
      "source": [
        "hz_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ2347buZISB"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qtgyIEBiJz7"
      },
      "source": [
        "def histogram(diff):  \n",
        "    n_bins = 250\n",
        "    x = diff\n",
        "    y = true_hz\n",
        "\n",
        "    plt.figure()\n",
        "    plt.hist(x, bins=n_bins)\n",
        "    #plt.xlim([-200, 200])\n",
        "    plt.ylim([0, 10000])\n",
        "    plt.axvline(np.median(x), color='k', linestyle='dashed', linewidth=2, label='median')\n",
        "    plt.axvline(np.mean(x), color='k', linestyle='solid', linewidth=2, label='mean')\n",
        "    plt.axvline(np.quantile(x, 0.05), color='k', linestyle='dotted', linewidth=2, label='5% quantile')\n",
        "    plt.axvline(np.quantile(x, 0.95), color='k', linestyle='dashdot', linewidth=2, label='95% quantile')\n",
        "    plt.xlabel(\"Error in Hertz\")\n",
        "    plt.ylabel(\"Number of Errors\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# histo = histogram(diff)\n",
        "# histo_true = histogram([x[0] - x[1] for x in filtered])"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFxKN2zZa_-s"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM1IhBo8sNwT"
      },
      "source": [
        "err = np.array([x[0]-x[1] for x in filtered])\n",
        "gt = np.array([x[0] for x in filtered])\n",
        "est = np.array([x[1] for x in filtered])\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(gt,err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60kyTZSnvfOk"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(gt[err < -50],est[err < -50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_ozKh80tFub"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(gt[est<35],err[est<35])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgj1DGAaAo0v"
      },
      "source": [
        "pred = model.predict(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxGCoAFhasse"
      },
      "source": [
        "for i in range(len(pred)):\n",
        "    plt.figure(i)\n",
        "    plt.plot(pred[i], 'b')\n",
        "    plt.plot(outp[i], 'g')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8J5dEclpXSG"
      },
      "source": [
        "pred = model.predict(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQrpOxrJpbhm"
      },
      "source": [
        "for i in range(len(pred)):\n",
        "    plt.figure(i)\n",
        "    plt.plot(pred[i], 'g')\n",
        "    plt.plot(out[i], 'b')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxNitqcPiLd3"
      },
      "source": [
        "for i in range(len(pred)):\n",
        "    plt.figure(i)\n",
        "    z = pred[i]\n",
        "    y = out[i]\n",
        "    plt.figure()\n",
        "    plt.plot(z, 'b')\n",
        "    plt.plot(y, 'r')\n",
        "    plt.plot(np.argmax(z),np.max(z),'x')\n",
        "    plt.plot(np.argmax(y),np.max(y),'x')\n",
        "    plt.ylim([0, 1.1])\n",
        "    plt.text(np.argmax(z)+10,np.max(z),f'max={np.max(z):.1f} @ bin {np.argmax(z)}')\n",
        "    plt.text(np.argmax(y)+10,np.max(y),f'max={np.max(y):.1f} @ bin {np.argmax(y)}')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
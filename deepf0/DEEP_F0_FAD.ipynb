{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEEP-F0.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wolfisberg/zhaw-ba-online/blob/main/deepf0/DEEP_F0_FAD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU5ZvlGglGDd"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Q42BY8BPSoL",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02e8b885-cd95-4895-cd2f-29086bdd8d37"
      },
      "source": [
        "!pip install mir_eval\n",
        "!pip install rt_pie_lib\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import scipy.interpolate\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import datetime\n",
        "import mir_eval\n",
        "import math\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mir_eval\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/fe/be4f7a59ed71938e21e89f23afe93eea0d39eb3e77f83754a12028cf1a68/mir_eval-0.6.tar.gz (87kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 21.1MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 20kB 15.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 40kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 61kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 6.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 81kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 4.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.4.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval) (1.15.0)\n",
            "Building wheels for collected packages: mir-eval\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.6-cp37-none-any.whl size=96515 sha256=be938c99a08b4c8d5b04213e59ad5f4f5462fe7964e5c84e371d343935d0a472\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/ce/30/730fa72addf275e49d90683b01b3613048b4be3bf7ff8eb6ec\n",
            "Successfully built mir-eval\n",
            "Installing collected packages: mir-eval\n",
            "Successfully installed mir-eval-0.6\n",
            "Collecting rt_pie_lib\n",
            "  Downloading https://files.pythonhosted.org/packages/a7/cf/723ed166d2e6929e94009a75f5ce98ea8dd83c4c5ad7c1334c891afe9f10/rt_pie_lib-0.1.12-py3-none-any.whl\n",
            "Requirement already satisfied: numpy<1.20,>=1.19 in /usr/local/lib/python3.7/dist-packages (from rt_pie_lib) (1.19.5)\n",
            "Requirement already satisfied: mir_eval<0.7,>=0.6 in /usr/local/lib/python3.7/dist-packages (from rt_pie_lib) (0.6)\n",
            "Collecting scipy<2.0.0,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e8/43ffca541d2f208d516296950b25fe1084b35c2881f4d444c1346ca75815/scipy-1.6.3-cp37-cp37m-manylinux1_x86_64.whl (27.4MB)\n",
            "\u001b[K     |████████████████████████████████| 27.4MB 213kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mir_eval<0.7,>=0.6->rt_pie_lib) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval<0.7,>=0.6->rt_pie_lib) (0.16.0)\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy, rt-pie-lib\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed rt-pie-lib-0.1.12 scipy-1.6.3\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8nh41ellB7K"
      },
      "source": [
        "# Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rz-Qd2TwFmZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWZIc9-WSItM",
        "collapsed": true
      },
      "source": [
        "# Audio\n",
        "SNR_RANGE = (-5.0,20.0) #dB\n",
        "FRAME_LENGTH = 256\n",
        "FRAME_STEP = 512\n",
        "MIN_RAND_GAIN = 0.05\n",
        "MAX_RAND_GAIN = 1.1\n",
        "SAMPLE_LENGTH = 1 #shorter than shortest noise/speech sample\n",
        "FS = 16000\n",
        "PITCH_SAMPLING_TIME = 0.01 # s\n",
        "PITCH_FRAME_LENGTH = 0.032 # s\n",
        "\n",
        "\n",
        "# Data\n",
        "BATCH_SIZE = 128\n",
        "NUM_FRAMES = 1 + (FS * SAMPLE_LENGTH - FRAME_LENGTH) // FRAME_STEP\n",
        "# NUM_FRAMES = 1\n",
        "\n",
        "# Training\n",
        "STEPS_PER_EPOCH = 500\n",
        "EPOCHS = 100\n",
        "VALIDATION_STEPS = 5\n",
        "\n",
        "\n",
        "# Directories\n",
        "_DATA_DIR = os.path.join('/content/drive/MyDrive/BA_2021/')\n",
        "_TFRECORDS_DIR = os.path.join(_DATA_DIR, 'tfrecords_fad')\n",
        "_NOISE_DIR = os.path.join(_DATA_DIR, 'tfrecords')\n",
        "\n",
        "SPEECH_DATA_TT_DIR = os.path.join(_TFRECORDS_DIR, 'speech', 'tt')\n",
        "NOISE_DATA_TT_DIR = os.path.join(_TFRECORDS_DIR, 'noise', 'tt')\n",
        "\n",
        "TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "\n",
        "# Misc\n",
        "SEED = 2\n",
        "\n",
        "\n",
        "# Parsing\n",
        "PARSING_CONFIG_NOISE = {\n",
        "    'data': tf.io.VarLenFeature(tf.string),\n",
        "    'data_sampling_rate': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_num_channels': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_width': tf.io.VarLenFeature(tf.int64),\n",
        "}\n",
        "\n",
        "PARSING_CONFIG_SPEECH = {\n",
        "    'data': tf.io.VarLenFeature(tf.string),\n",
        "    'data_sampling_rate': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_num_channels': tf.io.VarLenFeature(tf.int64),\n",
        "    'data_width': tf.io.VarLenFeature(tf.int64),\n",
        "    'pitch': tf.io.VarLenFeature(tf.float32),\n",
        "    'pitch_confidence': tf.io.VarLenFeature(tf.float32),\n",
        "}\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FARA0gp6hery"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-kwHYrpmCgl"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmb9w4ACwoUi"
      },
      "source": [
        "## Copy Data to Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYKlRsmDwsKM"
      },
      "source": [
        "DATA_DIR_LOCAL = '/content/data'\n",
        "\n",
        "if not os.path.exists(DATA_DIR_LOCAL):\n",
        "    os.mkdir(DATA_DIR_LOCAL)\n",
        "    \n",
        "    RECORD_DIR_LOCAL = os.path.join(DATA_DIR_LOCAL, 'tfrecords')\n",
        "    shutil.copytree(_TFRECORDS_DIR, RECORD_DIR_LOCAL)\n",
        "\n",
        "\n",
        "_TFRECORDS_DIR = os.path.join(DATA_DIR_LOCAL, 'tfrecords')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlkFt3Nvsqn-"
      },
      "source": [
        "## Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhwJchGumFSo"
      },
      "source": [
        "def _parse_noise_record(serialized_example):\n",
        "    parsed_features = tf.io.parse_single_example(serialized_example, features=PARSING_CONFIG_NOISE)\n",
        "    decoded_features = {\n",
        "        \"data_num_channels\": tf.cast(parsed_features[\"data_num_channels\"].values[0], tf.int32),\n",
        "        \"data_sampling_rate\": tf.cast(parsed_features[\"data_sampling_rate\"].values[0], tf.int32),\n",
        "        \"data_width\": tf.cast(parsed_features[\"data_width\"].values[0], tf.int32),\n",
        "    }\n",
        "    data = tf.io.decode_raw(parsed_features['data'].values[0], tf.int16)\n",
        "    decoded_features.update({\"data\": data})\n",
        "    return decoded_features\n",
        "\n",
        "\n",
        "def _parse_speech_record(serialized_example):\n",
        "    parsed_features = tf.io.parse_single_example(serialized_example, features=PARSING_CONFIG_SPEECH)\n",
        "    decoded_features = {\n",
        "        \"data_num_channels\": tf.cast(parsed_features[\"data_num_channels\"].values[0], tf.int32),\n",
        "        \"data_sampling_rate\": tf.cast(parsed_features[\"data_sampling_rate\"].values[0], tf.int32),\n",
        "        \"data_width\": tf.cast(parsed_features[\"data_width\"].values[0], tf.int32),\n",
        "        \"pitch\": tf.cast(parsed_features['pitch'].values, tf.float32),\n",
        "        \"pitch_confidence\": tf.cast(parsed_features['pitch_confidence'].values, tf.float32),\n",
        "    }\n",
        "    data = tf.io.decode_raw(parsed_features['data'].values[0], tf.int16)\n",
        "    decoded_features.update({\"data\": data})\n",
        "    return decoded_features\n",
        "\n",
        "\n",
        "def _mix_noisy_speech(speech, noise):\n",
        "    speech_pow = tf.math.reduce_euclidean_norm(speech)\n",
        "    noise_pow = tf.math.reduce_euclidean_norm(noise)\n",
        "\n",
        "    min_SNR = SNR_RANGE[0]\n",
        "    max_SNR = SNR_RANGE[1]\n",
        "    snr_current = 20.0*tf.math.log(speech_pow/noise_pow)/tf.math.log(10.0)\n",
        "    snr_target = tf.random.uniform((),minval=min_SNR,maxval=max_SNR)\n",
        "\n",
        "    noise = noise * tf.math.pow(10.0,(snr_current-snr_target)/20.0)\n",
        "    noisy_speech = speech+noise\n",
        "\n",
        "    return speech, noise, noisy_speech\n",
        "\n",
        "\n",
        "def _interpolate_pitch(pitch,t):\n",
        "    pitches = pitch.numpy()\n",
        "    t = t.numpy()\n",
        "    t_pitch = np.arange(0, len(pitch)) * PITCH_SAMPLING_TIME + PITCH_FRAME_LENGTH / 2\n",
        "    f = scipy.interpolate.interp1d(t_pitch, pitch, 'nearest')\n",
        "    return f(t).astype(np.float32)\n",
        "\n",
        "def convert_hz_to_cent(f,fref=10.0):\n",
        "    return mir_eval.melody.hz2cents(np.array(f), fref)\n",
        "\n",
        "def calc_bin(freq_cent, cents_per_bin = 20, lower_bound_freq=32.7):  \n",
        "    freq_cent = np.squeeze(freq_cent)\n",
        "    lower_bound_freq_cent = mir_eval.melody.hz2cents(np.array([lower_bound_freq]))\n",
        "    bin = (freq_cent - lower_bound_freq_cent) / np.array([cents_per_bin])\n",
        "    return np.clip(bin, 0, 359)\n",
        "\n",
        "def calc_y(f_groundtruth, n_bins = 360):\n",
        "    c_true = calc_bin(f_groundtruth)\n",
        "    return create_bin_vector(c_true)\n",
        "\n",
        "def create_bin_vector(c_true):\n",
        "    cis = np.arange(360)\n",
        "    y = [gaussian_blur(cis, i) for i in c_true]\n",
        "    return np.squeeze(y)\n",
        "    \n",
        "def gaussian_blur(ci, ctrue):\n",
        "    return np.exp(-(ci-ctrue)**2/(2.0*25.0**2))\n",
        "\n",
        "@tf.function\n",
        "def _interpolate_pitch_tf(pitch,t):\n",
        "    y = tf.py_function(_interpolate_pitch,[pitch,t], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "@tf.function\n",
        "def _convert_hz_to_cent(pitch):\n",
        "    y = tf.py_function(convert_hz_to_cent,[pitch], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "@tf.function\n",
        "def _calc_y(pitch_cents):\n",
        "    y = tf.py_function(calc_y,[pitch_cents], Tout=tf.float32)\n",
        "    return tf.squeeze(y)\n",
        "\n",
        "\n",
        "def _calc_features(speech_data, noise_data):\n",
        "    speech = tf.squeeze(tf.cast(speech_data[\"data\"], tf.float32))\n",
        "    noise = tf.squeeze(tf.cast(noise_data[\"data\"], tf.float32))\n",
        "    speech = speech / tf.int16.max\n",
        "    noise = noise / tf.int16.max\n",
        "\n",
        "    random_start_idx = int(tf.round(tf.random.uniform([], maxval=(\n",
        "             tf.cast(len(noise), tf.float32) - SAMPLE_LENGTH * FS - PITCH_SAMPLING_TIME))))\n",
        "    noise = noise[random_start_idx:random_start_idx + SAMPLE_LENGTH * FS]\n",
        "\n",
        "    random_start_idx = int(tf.round(tf.random.uniform([], minval=160, maxval=(\n",
        "            tf.cast(len(speech), tf.float32) - SAMPLE_LENGTH * FS - 256))))\n",
        "    speech = speech[random_start_idx:random_start_idx + SAMPLE_LENGTH * FS]  \n",
        "   \n",
        "\n",
        "    #SNR_range = SNR_RANGE\n",
        "    frame_length = FRAME_LENGTH\n",
        "    frame_step = FRAME_STEP\n",
        "    speech, noise, noisy = _mix_noisy_speech(speech, noise)\n",
        "\n",
        "    random_gain = tf.math.exp(\n",
        "        tf.random.uniform([], minval=tf.math.log(MIN_RAND_GAIN), maxval=tf.math.log(MAX_RAND_GAIN)))\n",
        "    noisy = random_gain * noisy\n",
        "\n",
        "    noisy_frames = tf.signal.frame(noisy, frame_length, frame_step)\n",
        "    speech_frames = tf.signal.frame(speech, frame_length, frame_step)\n",
        "    noisy_frames = tf.squeeze(noisy_frames)\n",
        "    speech_frames = tf.squeeze(speech_frames)\n",
        "    #noisy_stft = tf.signal.stft(noisy,frame_length,frame_step)\n",
        "    frame_times = random_start_idx / FS + tf.range(0, NUM_FRAMES) * frame_step / FS + frame_length / FS\n",
        "    \n",
        "    pitch = tf.squeeze(speech_data[\"pitch\"])    \n",
        "    pitch_confidence = tf.squeeze(speech_data[\"pitch_confidence\"])\n",
        "    #pitch = tf.where(pitch_confidence>config['pitch_confidence_threshold'],pitch,0)\n",
        "    pitch_interpolated = _interpolate_pitch_tf(pitch, frame_times)\n",
        "    pitch_interpolated_cents = _convert_hz_to_cent(pitch_interpolated)\n",
        "    pitch_bins = _calc_y(pitch_interpolated_cents)\n",
        "    return speech_frames, pitch_bins"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0TKt5eSs0SF"
      },
      "source": [
        "## Provide Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiU-wMWPs2dZ"
      },
      "source": [
        "def get_training_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_TR_DIR, file) for file in os.listdir(SPEECH_DATA_TR_DIR)])\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_TR_DIR, file) for file in os.listdir(NOISE_DATA_TR_DIR)])\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "    return dataset_features\n",
        "\n",
        "\n",
        "def get_validation_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_CV_DIR, file) for file in os.listdir(SPEECH_DATA_CV_DIR)])\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_CV_DIR, file) for file in os.listdir(NOISE_DATA_CV_DIR)])\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset_features\n",
        "\n",
        "\n",
        "def get_test_data():\n",
        "    speech_ds = tf.data.TFRecordDataset([os.path.join(SPEECH_DATA_TT_DIR, file) for file in os.listdir(SPEECH_DATA_TT_DIR)])\n",
        "    # speech_ds = speech_ds.map(_parse_speech_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "    speech_ds = speech_ds.map(_parse_speech_record).repeat(50).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "\n",
        "    noise_ds = tf.data.TFRecordDataset([os.path.join(NOISE_DATA_TT_DIR, file) for file in os.listdir(NOISE_DATA_TT_DIR)])\n",
        "    # noise_ds = noise_ds.map(_parse_noise_record).repeat(None).shuffle(buffer_size=1000, seed=SEED)\n",
        "    noise_ds = noise_ds.map(_parse_noise_record).repeat(50).shuffle(buffer_size=1000, seed=SEED)\n",
        "\n",
        "\n",
        "    dataset_combined = tf.data.Dataset.zip((speech_ds, noise_ds))\n",
        "    dataset_features = dataset_combined.map(_calc_features, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset_features = dataset_features.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    # just use if crepe without time component\n",
        "    dataset_features = dataset_features.unbatch().unbatch().shuffle(3000).batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset_features"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdIXYFTDoN1j"
      },
      "source": [
        "# Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmKx4gLkKjwQ"
      },
      "source": [
        "## DEEP-F0 without time component"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPygi-4sKooq"
      },
      "source": [
        "from tensorflow.keras.layers import Input, Reshape, Conv2D, BatchNormalization\n",
        "from tensorflow.keras.layers import AveragePooling2D, Dropout, Permute, Flatten, Dense, Add, ReLU\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def resblock(x, filters, kernelsize, dilationrate, name):\n",
        "    fx = Conv2D(filters, (kernelsize, 1), dilation_rate=(dilationrate, 1), padding='same',\n",
        "                   activation='relu', name=\"dilation-conv%d\" % name)(x)\n",
        "    fx = BatchNormalization()(fx)\n",
        "    fx = Conv2D(filters, 1, padding='same')(fx)\n",
        "    out = Add()([x,fx])\n",
        "    out = ReLU()(out)\n",
        "    return out\n",
        "\n",
        "def get_model_deepf0():\n",
        "    layers = 1\n",
        "    filters = 128\n",
        "    width = 512\n",
        "    strides = (16, 1)\n",
        "    dilation_rate = 8\n",
        "\n",
        "    x = Input(shape=(FRAME_LENGTH,), name='input', dtype='float32')\n",
        "    y = Reshape(target_shape=(FRAME_LENGTH, 1, 1), name='input-reshape')(x)\n",
        "\n",
        "\n",
        "    y = Conv2D(filters, (width, 1), strides=strides, padding='same',\n",
        "                activation='relu')(y)\n",
        "    for i in range(4):\n",
        "        y = resblock(y, filters, 64, dilation_rate, name=i)\n",
        "    y = AveragePooling2D(pool_size=(2, 1), strides=None, padding='valid',\n",
        "                        name=\"conv1d-avgpool\")(y)\n",
        "    y = Permute((2, 1, 3), name=\"transpose\")(y)\n",
        "    y = Flatten(name=\"flatten\")(y)\n",
        "    y = Dense(360, activation='sigmoid', name=\"classifier\")(y)\n",
        "   \n",
        "\n",
        "    model = Model(inputs=x, outputs=y)\n",
        "    model.compile('adam', 'binary_crossentropy', metrics=['mse', 'mae'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV-SpsYhaCNV"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2g6YW7mUtA64"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "uU1pyCDPm8C7"
      },
      "source": [
        "# dataset_training = get_training_data()\n",
        "# dataset_validation = get_validation_data()\n",
        "dataset_test = get_test_data()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dzEiCs_tDcJ"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poP21a6TnLHO"
      },
      "source": [
        "model = get_model_deepf0()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33_wEPK8nNfC"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9FxwYbUXD3_"
      },
      "source": [
        "tf.keras.utils.plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbVgnmcitIjt"
      },
      "source": [
        "## Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHZ4eMqMnchd",
        "collapsed": true
      },
      "source": [
        "%tensorboard --logdir /content/drive/MyDrive/BA_2021/deepf0/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPzG257AP4uR"
      },
      "source": [
        "# USE IF IT IS INITIAL TRAINING\n",
        "\n",
        "MODEL_USED = 'deepf0'\n",
        "LOG_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'logs', TIMESTAMP + '_2048_1024_100_Epochs')\n",
        "if not os.path.exists(LOG_DIR):\n",
        "    os.makedirs(LOG_DIR)\n",
        "CHECKPOINT_DIR = os.path.join(_DATA_DIR, MODEL_USED, 'checkpoints', TIMESTAMP + '_2048_1024_100_Epochs')\n",
        "if not os.path.exists(CHECKPOINT_DIR):\n",
        "    os.makedirs(CHECKPOINT_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tn0JRWrccNJH"
      },
      "source": [
        "# JUST USE IF CONTINUING TRAINING\n",
        "\n",
        "CHECKPOINT_DIR = '/content/drive/MyDrive/BA_2021/crepe/checkpoints/20210427-145400'\n",
        "LOGDIR = '/content/drive/MyDrive/BA_2021/crepe/logs/20210427-145400'\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/crepe/checkpoints', '20210427-145400', '50-2063.93.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "OMUc5cRQnSNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e969763-b402-4240-b049-4210f2cbafff"
      },
      "source": [
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(LOG_DIR, histogram_freq=1)\n",
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath=os.path.join(CHECKPOINT_DIR,'{epoch:02d}-{val_loss:.2f}.hdf5'))\n",
        "early_stopping =  tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=32, mode='min')\n",
        "\n",
        "callbacks = [checkpoint, tensorboard_callback, early_stopping]\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    dataset_training,\n",
        "    steps_per_epoch=500,\n",
        "    epochs=100,\n",
        "    # initial_epoch=30,\n",
        "    verbose = 1,\n",
        "    validation_data = dataset_validation,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks = callbacks)\n",
        "    \n",
        "loss = model.evaluate(dataset_test, steps=70)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "500/500 [==============================] - 32s 54ms/step - loss: 0.2359 - mse: 0.0358 - mae: 0.0920 - val_loss: 0.2277 - val_mse: 0.0369 - val_mae: 0.1098\n",
            "Epoch 2/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.2053 - mse: 0.0288 - mae: 0.0781 - val_loss: 0.2091 - val_mse: 0.0297 - val_mae: 0.0670\n",
            "Epoch 3/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1748 - mse: 0.0203 - mae: 0.0576 - val_loss: 0.2017 - val_mse: 0.0269 - val_mae: 0.0696\n",
            "Epoch 4/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1696 - mse: 0.0175 - mae: 0.0512 - val_loss: 0.1770 - val_mse: 0.0216 - val_mae: 0.0542\n",
            "Epoch 5/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1663 - mse: 0.0164 - mae: 0.0477 - val_loss: 0.1654 - val_mse: 0.0162 - val_mae: 0.0432\n",
            "Epoch 6/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1617 - mse: 0.0155 - mae: 0.0456 - val_loss: 0.1840 - val_mse: 0.0228 - val_mae: 0.0661\n",
            "Epoch 7/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1553 - mse: 0.0140 - mae: 0.0414 - val_loss: 0.1784 - val_mse: 0.0205 - val_mae: 0.0483\n",
            "Epoch 8/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1523 - mse: 0.0126 - mae: 0.0375 - val_loss: 0.1776 - val_mse: 0.0210 - val_mae: 0.0508\n",
            "Epoch 9/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1590 - mse: 0.0143 - mae: 0.0419 - val_loss: 0.1805 - val_mse: 0.0207 - val_mae: 0.0528\n",
            "Epoch 10/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1557 - mse: 0.0137 - mae: 0.0402 - val_loss: 0.1758 - val_mse: 0.0207 - val_mae: 0.0454\n",
            "Epoch 11/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1521 - mse: 0.0128 - mae: 0.0379 - val_loss: 0.1625 - val_mse: 0.0157 - val_mae: 0.0396\n",
            "Epoch 12/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1499 - mse: 0.0118 - mae: 0.0354 - val_loss: 0.2060 - val_mse: 0.0309 - val_mae: 0.0790\n",
            "Epoch 13/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1578 - mse: 0.0137 - mae: 0.0405 - val_loss: 0.1736 - val_mse: 0.0203 - val_mae: 0.0508\n",
            "Epoch 14/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1578 - mse: 0.0138 - mae: 0.0405 - val_loss: 0.1586 - val_mse: 0.0150 - val_mae: 0.0439\n",
            "Epoch 15/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1475 - mse: 0.0115 - mae: 0.0347 - val_loss: 0.1403 - val_mse: 0.0106 - val_mae: 0.0314\n",
            "Epoch 16/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1515 - mse: 0.0120 - mae: 0.0358 - val_loss: 0.1571 - val_mse: 0.0142 - val_mae: 0.0454\n",
            "Epoch 17/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1565 - mse: 0.0136 - mae: 0.0392 - val_loss: 0.1750 - val_mse: 0.0191 - val_mae: 0.0511\n",
            "Epoch 18/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1576 - mse: 0.0138 - mae: 0.0404 - val_loss: 0.1721 - val_mse: 0.0179 - val_mae: 0.0520\n",
            "Epoch 19/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1481 - mse: 0.0118 - mae: 0.0348 - val_loss: 0.1687 - val_mse: 0.0183 - val_mae: 0.0460\n",
            "Epoch 20/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1491 - mse: 0.0115 - mae: 0.0342 - val_loss: 0.1782 - val_mse: 0.0198 - val_mae: 0.0605\n",
            "Epoch 21/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1542 - mse: 0.0126 - mae: 0.0368 - val_loss: 0.1575 - val_mse: 0.0136 - val_mae: 0.0365\n",
            "Epoch 22/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1544 - mse: 0.0132 - mae: 0.0383 - val_loss: 0.1560 - val_mse: 0.0152 - val_mae: 0.0417\n",
            "Epoch 23/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1467 - mse: 0.0113 - mae: 0.0335 - val_loss: 0.1763 - val_mse: 0.0194 - val_mae: 0.0457\n",
            "Epoch 24/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1497 - mse: 0.0113 - mae: 0.0339 - val_loss: 0.1689 - val_mse: 0.0179 - val_mae: 0.0477\n",
            "Epoch 25/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1554 - mse: 0.0128 - mae: 0.0372 - val_loss: 0.1453 - val_mse: 0.0123 - val_mae: 0.0366\n",
            "Epoch 26/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1538 - mse: 0.0129 - mae: 0.0372 - val_loss: 0.1612 - val_mse: 0.0169 - val_mae: 0.0409\n",
            "Epoch 27/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1440 - mse: 0.0105 - mae: 0.0314 - val_loss: 0.1670 - val_mse: 0.0180 - val_mae: 0.0418\n",
            "Epoch 28/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1474 - mse: 0.0111 - mae: 0.0325 - val_loss: 0.1617 - val_mse: 0.0153 - val_mae: 0.0366\n",
            "Epoch 29/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1495 - mse: 0.0116 - mae: 0.0338 - val_loss: 0.1601 - val_mse: 0.0155 - val_mae: 0.0452\n",
            "Epoch 30/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1559 - mse: 0.0132 - mae: 0.0385 - val_loss: 0.1591 - val_mse: 0.0138 - val_mae: 0.0425\n",
            "Epoch 31/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1464 - mse: 0.0110 - mae: 0.0327 - val_loss: 0.1568 - val_mse: 0.0155 - val_mae: 0.0397\n",
            "Epoch 32/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1462 - mse: 0.0108 - mae: 0.0317 - val_loss: 0.1639 - val_mse: 0.0143 - val_mae: 0.0405\n",
            "Epoch 33/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1549 - mse: 0.0130 - mae: 0.0372 - val_loss: 0.1702 - val_mse: 0.0175 - val_mae: 0.0375\n",
            "Epoch 34/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1505 - mse: 0.0118 - mae: 0.0345 - val_loss: 0.1579 - val_mse: 0.0163 - val_mae: 0.0395\n",
            "Epoch 35/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1459 - mse: 0.0107 - mae: 0.0317 - val_loss: 0.1587 - val_mse: 0.0155 - val_mae: 0.0439\n",
            "Epoch 36/100\n",
            "500/500 [==============================] - 25s 50ms/step - loss: 0.1480 - mse: 0.0108 - mae: 0.0320 - val_loss: 0.1668 - val_mse: 0.0162 - val_mae: 0.0469\n",
            "Epoch 37/100\n",
            "500/500 [==============================] - 25s 50ms/step - loss: 0.1511 - mse: 0.0119 - mae: 0.0343 - val_loss: 0.1582 - val_mse: 0.0130 - val_mae: 0.0422\n",
            "Epoch 38/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1515 - mse: 0.0122 - mae: 0.0352 - val_loss: 0.1643 - val_mse: 0.0160 - val_mae: 0.0403\n",
            "Epoch 39/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1442 - mse: 0.0105 - mae: 0.0314 - val_loss: 0.1689 - val_mse: 0.0185 - val_mae: 0.0426\n",
            "Epoch 40/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1467 - mse: 0.0107 - mae: 0.0315 - val_loss: 0.1672 - val_mse: 0.0178 - val_mae: 0.0405\n",
            "Epoch 41/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1533 - mse: 0.0122 - mae: 0.0353 - val_loss: 0.1595 - val_mse: 0.0136 - val_mae: 0.0384\n",
            "Epoch 42/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1513 - mse: 0.0122 - mae: 0.0351 - val_loss: 0.1576 - val_mse: 0.0146 - val_mae: 0.0369\n",
            "Epoch 43/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1433 - mse: 0.0102 - mae: 0.0305 - val_loss: 0.1522 - val_mse: 0.0130 - val_mae: 0.0360\n",
            "Epoch 44/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1484 - mse: 0.0111 - mae: 0.0327 - val_loss: 0.1669 - val_mse: 0.0173 - val_mae: 0.0437\n",
            "Epoch 45/100\n",
            "500/500 [==============================] - 25s 49ms/step - loss: 0.1519 - mse: 0.0119 - mae: 0.0345 - val_loss: 0.1641 - val_mse: 0.0173 - val_mae: 0.0427\n",
            "Epoch 46/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1519 - mse: 0.0121 - mae: 0.0353 - val_loss: 0.1579 - val_mse: 0.0154 - val_mae: 0.0385\n",
            "Epoch 47/100\n",
            "500/500 [==============================] - 24s 49ms/step - loss: 0.1399 - mse: 0.0096 - mae: 0.0286 - val_loss: 0.1783 - val_mse: 0.0196 - val_mae: 0.0440\n",
            "70/70 [==============================] - 5s 32ms/step - loss: 0.1571 - mse: 0.0139 - mae: 0.0335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVozVO6-vtO3"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msEYwMhNddcK"
      },
      "source": [
        "# 1024 / 512\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/deepf0/checkpoints', '20210502-204318_1024_512_100_Epochs', '87-0.16.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb4YnOFA_dqZ"
      },
      "source": [
        "# 512 / 256\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/deepf0/checkpoints', '20210503-142217_512_256_100_Epochs', '48-0.22.hdf5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM3NbC0mkbmg"
      },
      "source": [
        "# 256 / 128\n",
        "model.load_weights(os.path.join('/content/drive/MyDrive/BA_2021/deepf0/checkpoints', '20210503-193625_256_128_100_Epochs', '91-0.22.hdf5'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmvJr2v9lCmz"
      },
      "source": [
        "from rt_pie_lib import converters\n",
        "def prediction():\n",
        "    predicted_c = []\n",
        "    true_c = []\n",
        "    inp_vector = []\n",
        "    predicted_vector = []\n",
        "    for inp, outp in dataset_test:\n",
        "        predicted = model.predict(inp)\n",
        "        predicted_vector.append(predicted)\n",
        "        inp_vector.append(outp) \n",
        "        true_cents = converters.convert_bin_to_local_average_cents(outp)\n",
        "        true_c.append(true_cents)\n",
        "        predicted_cents = converters.convert_bin_to_local_average_cents(np.squeeze(predicted))\n",
        "        predicted_c.append(predicted_cents)\n",
        "\n",
        "    predicted_vector = np.reshape(np.array(predicted_vector), ((len(predicted_vector) * len(predicted_vector[0]), 360)))\n",
        "    inp_vector = np.reshape(np.array(inp_vector), ((len(inp_vector) * len(inp_vector[0]), 360)))\n",
        "    \n",
        "    true_c = np.reshape(np.array(true_c), (1, (len(true_c)*len(true_c[0]))))\n",
        "    true_c = np.squeeze(true_c)\n",
        "    true_hz = converters.convert_cent_to_hz(true_c)\n",
        "    predicted_c = np.reshape(np.array(predicted_c), (1, (len(predicted_c)*len(predicted_c[0]))))\n",
        "    predicted_c = np.squeeze(predicted_c)\n",
        "    predicted_hz = converters.convert_cent_to_hz(predicted_c)\n",
        "    diff = true_hz - predicted_hz\n",
        "    return predicted_hz, true_hz, true_c, predicted_c, diff, inp_vector, predicted_vector"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4R7WMLSRbfyp"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ucPJnobUMw"
      },
      "source": [
        "from rt_pie_lib import converters\n",
        "def prediction():\n",
        "    predicted_c = []\n",
        "    true_c = []\n",
        "    inp_vector = []\n",
        "    predicted_vector = []\n",
        "    for inp, outp in dataset_test:\n",
        "        predicted = model.predict(inp)\n",
        "        predicted_vector.append(predicted)\n",
        "        inp_vector.append(outp) \n",
        "        true_cents = converters.convert_bin_to_local_average_cents(np.squeeze(outp))\n",
        "        true_c.append(true_cents)\n",
        "        predicted_cents = converters.convert_bin_to_local_average_cents_lowest_maxima(predicted)\n",
        "        predicted_c.append(predicted_cents)\n",
        "\n",
        "    predicted_vector = np.reshape(np.array(predicted_vector), ((len(predicted_vector) * len(predicted_vector[0]), 360)))\n",
        "    inp_vector = np.reshape(np.array(inp_vector), ((len(inp_vector) * len(inp_vector[0]), 360)))\n",
        "    \n",
        "    true_c = np.reshape(np.array(true_c), (1, (len(true_c)*len(true_c[0]))))\n",
        "    true_c = np.squeeze(true_c)\n",
        "    true_hz = converters.convert_cent_to_hz(true_c)\n",
        "    predicted_c = np.reshape(np.array(predicted_c), (1, (len(predicted_c)*len(predicted_c[0]))))\n",
        "    predicted_c = np.squeeze(predicted_c)\n",
        "    predicted_hz = converters.convert_cent_to_hz(predicted_c)\n",
        "    diff = true_hz - predicted_hz\n",
        "    return predicted_hz, true_hz, true_c, predicted_c, diff, inp_vector, predicted_vector"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh3HIl3f7ONH"
      },
      "source": [
        "predicted_hz, true_hz, true_cent, predicted_cent, diff, inp_vector, predicted_vector = prediction()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4LPGpFaYwvU"
      },
      "source": [
        "### Prediction Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUs_jXsA-8h5"
      },
      "source": [
        "## Hertz filter\n",
        "combined = zip(true_hz, predicted_hz)\n",
        "filtered = [x for x in list(combined) if x[0] > 60 and x[1] > 60 and x[1] < 400]\n",
        "filtered_unzipped = np.array(list(zip(*filtered)))\n",
        "diff_filtered = filtered_unzipped[0] - filtered_unzipped[1]\n",
        "\n",
        "## Cent filter\n",
        "combined_cent = zip(true_cent, predicted_cent)\n",
        "filtered_cent = [x for x in list(combined_cent) if x[0] > 3101.95500087 and x[1] > 3101.95500087]\n",
        "filtered_c_unzipped = np.array(list(zip(*filtered_cent)))\n",
        "diff_filtered_cent = filtered_c_unzipped[0] - filtered_c_unzipped[1]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAMZz2UdkylA"
      },
      "source": [
        "## Hz Values with factor 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNSM6rADKWzQ"
      },
      "source": [
        "counter = 0\n",
        "trues = np.array([])\n",
        "preds = np.array([])\n",
        "for i in range(len(diff)):\n",
        "    if diff[i] < -50  and true_hz[i] > 60:\n",
        "        plt.figure(i)\n",
        "        plt.plot(inp_vector[i], 'r')\n",
        "        plt.plot(predicted_vector[i], 'b')\n",
        "        plt.plot(np.argmax(inp_vector[i]),np.max(inp_vector[i]),'x')\n",
        "        plt.plot(np.argmax(predicted_vector[i]),np.max(predicted_vector[i]),'x')\n",
        "        plt.text(np.argmax(inp_vector[i])+10,np.max(inp_vector[i]),f'max={np.max(inp_vector[i]):.1f} @ bin {np.argmax(inp_vector[i])}')\n",
        "        plt.text(np.argmax(predicted_vector[i])+10,np.max(predicted_vector[i]),f'max={np.max(predicted_vector[i]):.1f} @ bin {np.argmax(predicted_vector[i])}')\n",
        "        plt.show()\n",
        "\n",
        "        \n",
        "        print('True Hz: ', true_hz[i], 'Predicted Hz: ',predicted_hz[i])\n",
        "        trues = np.append(trues, filtered_unzipped[0][i])\n",
        "        preds = np.append(preds, filtered_unzipped[1][i])\n",
        "        # counter += 1\n",
        "        # if counter == 60:\n",
        "        #     break   \n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRJb_B_ryvm5",
        "outputId": "08b9c6da-043a-47e4-8d8a-5ee05f369f17"
      },
      "source": [
        "divided = np.divide(preds, trues)\n",
        "np.mean(divided)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.621543653541332"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-AXsfqli1Nl"
      },
      "source": [
        "## Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zr6y9h0_cCRJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "outputId": "7eba1004-b1b8-40a6-e6a1-f72da15dfba7"
      },
      "source": [
        "from rt_pie_lib import metrics\n",
        "hz_metrics = metrics.get_hz_metrics(filtered_unzipped[0], filtered_unzipped[1], print_output=True, rpa_relative_tolerance=0.05)\n",
        "rpa_cent = metrics.raw_pitch_accuracy_cent(filtered_c_unzipped[0], filtered_c_unzipped[1])\n",
        "print(rpa_cent)\n",
        "hist = histogram(diff_filtered)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min abs err [Hz] _______ 0.0\n",
            "Max abs err [Hz] _____ 172.2\n",
            "Mean err [Hz] ________ -2.01\n",
            "Median [Hz] __________ -0.01\n",
            "MAE [Hz] _____________ 14.95\n",
            "StdDev [Hz] __________ 25.68\n",
            "5% quant err [Hz] ___ -39.43\n",
            "95% quant err [Hz] ___ 31.67\n",
            "RPA [Hz] _____________ 51.92\n",
            "31.387651943675532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9y3oZ8LQKZV9"
      },
      "source": [
        "hz_metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ2347buZISB"
      },
      "source": [
        "## Plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qtgyIEBiJz7"
      },
      "source": [
        "def histogram(diff):  \n",
        "    n_bins = 250\n",
        "    x = diff\n",
        "    y = true_hz\n",
        "\n",
        "    plt.figure(figsize=[16, 9])\n",
        "    plt.hist(x, bins=n_bins)\n",
        "    #plt.xlim([-200, 200])\n",
        "    plt.ylim([0, 4000])\n",
        "    plt.axvline(np.median(x), color='k', linestyle='dashed', linewidth=2, label='median')\n",
        "    plt.axvline(np.mean(x), color='k', linestyle='solid', linewidth=2, label='mean')\n",
        "    plt.axvline(np.quantile(x, 0.05), color='k', linestyle='dotted', linewidth=2, label='5% quantile')\n",
        "    plt.axvline(np.quantile(x, 0.95), color='k', linestyle='dashdot', linewidth=2, label='95% quantile')\n",
        "    plt.xlabel(\"Error in Hertz\")\n",
        "    plt.ylabel(\"Number of Errors\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# histo = histogram(diff)\n",
        "# histo_true = histogram([x[0] - x[1] for x in filtered])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFxKN2zZa_-s"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hM1IhBo8sNwT"
      },
      "source": [
        "err = np.array([x[0]-x[1] for x in filtered])\n",
        "gt = np.array([x[0] for x in filtered])\n",
        "est = np.array([x[1] for x in filtered])\n",
        "\n",
        "plt.figure()\n",
        "plt.scatter(gt,err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60kyTZSnvfOk"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(gt[err < -50],est[err < -50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_ozKh80tFub"
      },
      "source": [
        "plt.figure()\n",
        "plt.scatter(gt[est<35],err[est<35])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgj1DGAaAo0v"
      },
      "source": [
        "pred = model.predict(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxGCoAFhasse"
      },
      "source": [
        "for i in range(len(pred)):\n",
        "    plt.figure(i)\n",
        "    plt.plot(pred[i], 'b')\n",
        "    plt.plot(outp[i], 'g')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8J5dEclpXSG"
      },
      "source": [
        "pred = model.predict(inp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQrpOxrJpbhm"
      },
      "source": [
        "for i in range(len(pred)):\n",
        "    plt.figure(i)\n",
        "    plt.plot(pred[i], 'g')\n",
        "    plt.plot(out[i], 'b')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxNitqcPiLd3"
      },
      "source": [
        "for i in range(len(pred)):\n",
        "    plt.figure(i)\n",
        "    z = pred[i]\n",
        "    y = out[i]\n",
        "    plt.figure()\n",
        "    plt.plot(z, 'b')\n",
        "    plt.plot(y, 'r')\n",
        "    plt.plot(np.argmax(z),np.max(z),'x')\n",
        "    plt.plot(np.argmax(y),np.max(y),'x')\n",
        "    plt.ylim([0, 1.1])\n",
        "    plt.text(np.argmax(z)+10,np.max(z),f'max={np.max(z):.1f} @ bin {np.argmax(z)}')\n",
        "    plt.text(np.argmax(y)+10,np.max(y),f'max={np.max(y):.1f} @ bin {np.argmax(y)}')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}